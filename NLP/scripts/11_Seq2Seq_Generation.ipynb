{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Important Libraries"
      ],
      "metadata": {
        "id": "jJw0-8GayNJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX9m_9P-yA6d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# BART doc: https://huggingface.co/docs/transformers/en/model_doc/bart\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple LSTM-Based Seq2Seq Model"
      ],
      "metadata": {
        "id": "HVknjtpihE6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "NUM_LAYERS = 1\n",
        "LR = 0.001\n",
        "MAX_LEN = 30\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "PAD_IDX = tokenizer.pad_token_id\n",
        "SOS_IDX = tokenizer.cls_token_id or tokenizer.bos_token_id or 101\n",
        "EOS_IDX = tokenizer.sep_token_id or tokenizer.eos_token_id or 102\n",
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "\n",
        "# Dummy summarization data\n",
        "texts = [\n",
        "    \"The cat sat on the mat and looked at the dog.\",\n",
        "    \"The stock market crashed due to inflation concerns.\",\n",
        "    \"Artificial intelligence is transforming many industries.\",\n",
        "]\n",
        "\n",
        "summaries = [\n",
        "    \"Cat and dog on mat.\",\n",
        "    \"Market crashed from inflation.\",\n",
        "    \"AI changing industries.\",\n",
        "]"
      ],
      "metadata": {
        "id": "UhpRMFopgl35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to tokenize a given list of sentences\n",
        "def encode_batch(sentences):\n",
        "    tokens = tokenizer(\n",
        "        sentences,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return tokens['input_ids'].to(device)\n",
        "\n",
        "src = encode_batch(texts)\n",
        "trg = encode_batch(summaries)"
      ],
      "metadata": {
        "id": "tP5OlY-8ixwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining an Encoder\n",
        "# nn.Module doc: https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer - https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
        "\n",
        "        # Define LSTM - https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # Get embeddings for input tokens\n",
        "        embedded = self.embedding(src)\n",
        "\n",
        "        #Pass embeddings through LSTM to get hidden and cell states\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "# Defining a Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        # Similar to encoder, except there is a language modeling head (linear projection layer) at the end of it\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "\n",
        "        # Language model head - linear layer that projects the hid_dim dimension to vocab_size\n",
        "        self.fc_out = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # One forward step of the decoder (similar to encoder)\n",
        "        input = input.unsqueeze(1)  # [batch_size, 1]\n",
        "        embedded = self.embedding(input)\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "\n",
        "        # Project the LSTM output into logits (from which individual token probabilities can be computed)\n",
        "        logits = self.fc_out(output.squeeze(1))\n",
        "        return logits, hidden, cell\n",
        "\n",
        "# Combining encoder and decoder into a Seq2Seq Model\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        batch_size, trg_len = trg.shape\n",
        "\n",
        "        # Initializing a tensor which we will use to store the output vectors computed at each decoding step\n",
        "        outputs = torch.zeros(batch_size, trg_len, VOCAB_SIZE).to(device)\n",
        "\n",
        "        # We get the hidden and cell states from the encoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # Now, we want the decoder to start generating the summary\n",
        "        # So, we pass the first target token (<bos> token)\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # For the current input token, run it through the decoder for one step and get the updated hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            # Save the output (logits) for later use\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            # The input for the next step of decoding is set to the CURRENT highest probability token\n",
        "            # Doc: https://docs.pytorch.org/docs/stable/generated/torch.Tensor.argmax.html\n",
        "            input = output.argmax(1)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "bZLJY7YLi6VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing our Seq2Seq model\n",
        "enc = Encoder(VOCAB_SIZE, EMB_DIM, HID_DIM, NUM_LAYERS)\n",
        "dec = Decoder(VOCAB_SIZE, EMB_DIM, HID_DIM, NUM_LAYERS)\n",
        "model = Seq2Seq(enc, dec).to(device)\n",
        "\n",
        "# Defining optimizer and loss function for training\n",
        "# Adam optimizer doc: https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
        "# CE Loss doc: https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "# Training loop (tiny demo)\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    # This zeroes-out the gradients computed at the previous step\n",
        "    # Doc: https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Getting an output from the model\n",
        "    output = model(src, trg) # Tensor of size [batch_size, trg_len, vocab_size]\n",
        "\n",
        "    # Now, we compute the CE-loss between the predicted output logits and the ground-truth target tokens\n",
        "    output = output.reshape(-1, VOCAB_SIZE)\n",
        "    trg_y = trg.reshape(-1)\n",
        "    loss = criterion(output, trg_y)\n",
        "\n",
        "    # Computes gradients for one step of backward propagation\n",
        "    # Doc: https://docs.pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
        "    loss.backward()\n",
        "\n",
        "    # Updates model weights based on computed gradients\n",
        "    # Doc: https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Inference\n",
        "def summarize(sentence, max_len=MAX_LEN):\n",
        "\n",
        "    # Sets the model to evaluation model (no weight updates will happen)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Tokenize the given sentence and pass it through the model encoder\n",
        "        src = encode_batch([sentence])\n",
        "        hidden, cell = model.encoder(src)\n",
        "        input = torch.tensor([SOS_IDX]).to(device) # Input passed to decoder\n",
        "        summary = [input.item()] # Tokens of summary\n",
        "\n",
        "        for _ in range(max_len):\n",
        "\n",
        "            # Get the decoder's output for the current input\n",
        "            output, hidden, cell = model.decoder(input, hidden, cell)\n",
        "\n",
        "            # The predicted token is that which has the highest probability\n",
        "            pred = output.argmax(1)\n",
        "\n",
        "            # If the model predicts an End-of-Sentence or Padding Token, we stop generating further\n",
        "            token_id = pred.item()\n",
        "            if token_id == EOS_IDX or token_id == PAD_IDX:\n",
        "                break\n",
        "\n",
        "            # Otherwise, we append the generated token to our summary\n",
        "            summary.append(token_id)\n",
        "\n",
        "            # Input for next step is the token predicted during the current step (autoregressive)\n",
        "            input = pred\n",
        "\n",
        "        # Use the tokenizer to decoder (\"de-tokenize\") the summary\n",
        "        return tokenizer.decode(summary, skip_special_tokens=True)\n",
        "\n",
        "# Generating summaries\n",
        "print(\"\\nSample Summaries:\")\n",
        "for text in texts:\n",
        "    print(f\"TEXT: {text}\")\n",
        "    print(f\"SUMMARY: {summarize(text)}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIAbJJ7cjetq",
        "outputId": "6ca2841b-7a68-43e3-e594-096c86920a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 10.3213\n",
            "Epoch 2/10, Loss: 10.2706\n",
            "Epoch 3/10, Loss: 10.1675\n",
            "Epoch 4/10, Loss: 9.9936\n",
            "Epoch 5/10, Loss: 9.8127\n",
            "Epoch 6/10, Loss: 9.4919\n",
            "Epoch 7/10, Loss: 8.6630\n",
            "Epoch 8/10, Loss: 7.7821\n",
            "Epoch 9/10, Loss: 6.8644\n",
            "Epoch 10/10, Loss: 5.9014\n",
            "\n",
            "Sample Summaries:\n",
            "TEXT: The cat sat on the mat and looked at the dog.\n",
            "SUMMARY: ai and.......\n",
            "--------------------------------------------------\n",
            "TEXT: The stock market crashed due to inflation concerns.\n",
            "SUMMARY: ai and.......\n",
            "--------------------------------------------------\n",
            "TEXT: Artificial intelligence is transforming many industries.\n",
            "SUMMARY: ai and.......\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq Generation: Summarization as an Example"
      ],
      "metadata": {
        "id": "wh6-lftKdOI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By default, all matrix computations utilize the CPU.\n",
        "# However, you can instead utilize GPUs for the same since they are much faster at performing such operations\n",
        "# To do so, I am setting the 'device' variable to 'cuda' (NVIDIA GPU) if a GPU is available. Otherwise, it is set to 'cpu'.\n",
        "# Use '.to(device)' to shift tensors/models to a particular device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# The .from_pretrained() method is used to load a pre-trained model/tokenizer\n",
        "# doc: https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(device)\n",
        "tkr = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"
      ],
      "metadata": {
        "id": "FmR438-h06jY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some sample article excerpts that we want our model to summarize\n",
        "# Sources: https://en.wikipedia.org/wiki/Tiger, https://en.wikipedia.org/wiki/Lion, https://en.wikipedia.org/wiki/Snake\n",
        "text = [\n",
        "    \"The tiger (Panthera tigris) is a large cat and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two subspecies, mainland Asian tigers and the island tigers of the Sunda Islands. Throughout the tiger's range, it inhabits mainly forests, from coniferous and temperate broadleaf and mixed forests in the Russian Far East and Northeast China to tropical and subtropical moist broadleaf forests on the Indian subcontinent and Southeast Asia. The tiger is an apex predator and preys mainly on ungulates, which it takes by ambush. It lives a mostly solitary life and occupies home ranges, defending these from individuals of the same sex. The range of a male tiger overlaps with that of multiple females with whom he mates. Females give birth to usually two or three cubs that stay with their mother for about two years. When becoming independent, they leave their mother's home range and establish their own. \",\n",
        "    \"The lion (Panthera leo) is a large cat of the genus Panthera, currently ranging only in Sub-Saharan Africa and India. It has a muscular, broad-chested body; a short, rounded head; round ears; and a dark, hairy tuft at the tip of its tail. It is sexually dimorphic; adult male lions are larger than females and have a more prominent mane that usually obscures the ears and extends to the shoulders. The lion inhabits grasslands, savannahs, and shrublands. It is an apex and keystone predator, preying mostly on medium-sized and large ungulates. It is usually more diurnal than other wild cats, but when persecuted, it adapts to being active at night and at twilight. It is a social species, forming groups called prides. A lion pride consists of related females and cubs, and a few or one adult male who is unrelated to the females. Groups of female lions usually hunt together. Adult males often compete to keep or gain that membership in the pride. \",\n",
        "    \"Snakes are elongated limbless reptiles of the suborder Serpentes (/sɜːrˈpɛntiːz/).[2] Cladistically squamates, snakes are ectothermic, amniote vertebrates covered in overlapping scales much like other members of the group. Many species of snakes have skulls with several more joints than their lizard ancestors and relatives, enabling them to swallow prey much larger than their heads (cranial kinesis). To accommodate their narrow bodies, snakes' paired organs (such as kidneys) appear one in front of the other instead of side by side, and most only have one functional lung. Some species retain a pelvic girdle with a pair of vestigial claws on either side of the cloaca. Lizards have independently evolved elongate bodies without limbs or with greatly reduced limbs at least twenty-five times via convergent evolution, leading to many lineages of legless lizards.[3] These resemble snakes, but several common groups of legless lizards have eyelids and external ears, which snakes lack, although this rule is not universal (see Amphisbaenia, Dibamidae, and Pygopodidae). Living snakes are found on every continent except Antarctica, and on most smaller land masses; exceptions include some large islands, such as Ireland, Iceland, Greenland, and the islands of New Zealand, as well as many small islands of the Atlantic and central Pacific oceans.[4] Additionally, sea snakes are widespread throughout the Indian and Pacific oceans. Around thirty families are currently recognized, comprising about 520 genera and about more than 4,170 species.[5] They range in size from the tiny, 10.4 cm-long (4.1 in) Barbados threadsnake[6] to the reticulated python of 6.95 meters (22.8 ft) in length.[7] The fossil species Titanoboa cerrejonensis was 12.8 meters (42 ft) long.[8] Snakes are thought to have evolved from either burrowing or aquatic lizards, perhaps during the Jurassic period, with the earliest known fossils dating to between 143 and 167 Ma ago.[9][10] The diversity of modern snakes appeared during the Paleocene epoch (c. 66 to 56 Ma ago, after the Cretaceous–Paleogene extinction event). The oldest preserved descriptions of snakes can be found in the Brooklyn Papyrus. \"\n",
        "]"
      ],
      "metadata": {
        "id": "nSW9_UZ81ChT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we need to tokenize our text so that the model can actually understand it\n",
        "# Tokenizer doc: https://huggingface.co/docs/transformers/en/fast_tokenizers\n",
        "# Padding and truncation guide: https://huggingface.co/docs/transformers/en/pad_truncation\n",
        "tkr_out = tkr(\n",
        "    text,\n",
        "    max_length=256,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "#The output of tokenization is a dictionary containing:\n",
        "# 1. Input IDs (text converted into integer tokens)\n",
        "# 2. Attention mask that differentiates between padding & non-padding tokens (1 = non-padding token, 0 = padding token)\n",
        "print(tkr_out)"
      ],
      "metadata": {
        "id": "68Kc56Gk99s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f337a2c4-c27d-4677-b6c0-7b7cf244a0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    0,   133, 23921,    36,   510,   927,  1843,   102,   326,  1023,\n",
            "          4663,    43,    16,    10,   739,  4758,     8,    10,   919,     9,\n",
            "             5, 44878, 15148,   102,  3763,     7,  1817,     4,    85,    34,\n",
            "            10,  2247,     6, 26163,   809,    19,    10,   739,   471,     8,\n",
            "         40844,     6,    10,   251,  7886,     8,  8978, 15503,    19,   909,\n",
            "             6,  2260, 12194, 26224,     4,    85,    16, 10341,  8967,    88,\n",
            "          1117,   485,  2849, 42826,     6,   600,   103, 11865,   129,    80,\n",
            "          2849, 42826,     6, 11280,  3102, 36054,     8,     5,  2946, 36054,\n",
            "             9,     5, 12282,   102,  8594,     4, 13231,     5, 23921,    18,\n",
            "          1186,     6,    24, 42226,  2629,  4412, 14275,     6,    31,  2764,\n",
            "         14087,  1827,     8, 18586,   877,  4007, 24999,     8,  4281, 14275,\n",
            "            11,     5,  1083,  4256,   953,     8,  9564,   436,     7, 10602,\n",
            "             8, 30757,  6884,  3569, 34257,  4007, 24999, 14275,    15,     5,\n",
            "          1362,  2849, 10800, 19336,     8,  6079,  1817,     4,    20, 23921,\n",
            "            16,    41, 19559, 25293,     8,  1198,  2459,  4412,    15,   542,\n",
            "           571, 15719,     6,    61,    24,  1239,    30, 30382,     4,    85,\n",
            "          1074,    10,  2260, 24429,   301,     8, 32559,   184, 16296,     6,\n",
            "          5261,   209,    31,  2172,     9,     5,   276,  2099,     4,    20,\n",
            "          1186,     9,    10,  2943, 23921, 31669,  7527,    19,    14,     9,\n",
            "          1533, 16856,    19,  2661,    37, 18779,     4, 46452,   492,  3113,\n",
            "             7,  2333,    80,    50,   130, 18383,    29,    14,  1095,    19,\n",
            "            49,   985,    13,    59,    80,   107,     4,   520,  1959,  2222,\n",
            "             6,    51,   989,    49,   985,    18,   184,  1186,     8,  5242,\n",
            "            49,   308,     4,  1437,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1],\n",
            "        [    0,   133, 15587,    36,   510,   927,  1843,   102,  2084,   139,\n",
            "            43,    16,    10,   739,  4758,     9,     5, 44878, 15148,   102,\n",
            "             6,   855,  6272,   129,    11,  4052,    12, 27692,  1327,     8,\n",
            "           666,     4,    85,    34,    10, 26163,     6,  4007,    12,  2871,\n",
            "         16460,   809,   131,    10,   765,     6, 14439,   471,   131,  1062,\n",
            "         12137,   131,     8,    10,  2933,     6, 42175, 13145,  2543,    23,\n",
            "             5,  4767,     9,    63,  7886,     4,    85,    16,  5912, 14548,\n",
            "         31724,   636,   131,  4194,  2943, 25711,    32,  2514,    87, 16856,\n",
            "             8,    33,    10,    55,  5395,   313,   242,    14,  2333, 33718,\n",
            "          4123,     5, 12137,     8, 14269,     7,     5, 10762,     4,    20,\n",
            "         15587, 42226,  2629,  6964,  8391,     6, 14065, 25984,    29,     6,\n",
            "             8, 15383,  1792,  8391,     4,    85,    16,    41, 19559,     8,\n",
            "           762,  4670, 25293,     6,  1198,  4048,  2260,    15,  4761,    12,\n",
            "          8407,     8,   739,   542,   571, 15719,     4,    85,    16,  2333,\n",
            "            55,  2269, 37734,    87,    97,  3418, 10017,     6,    53,    77,\n",
            "         33338,     6,    24,  9037,    29,     7,   145,  2171,    23,   363,\n",
            "             8,    23, 38262,     4,    85,    16,    10,   592,  4707,     6,\n",
            "         12748,  1134,   373,  3349,  4376,     4,    83, 15587,  7040, 10726,\n",
            "             9,  1330, 16856,     8, 18383,    29,     6,     8,    10,   367,\n",
            "            50,    65,  4194,  2943,    54,    16, 16354,     7,     5, 16856,\n",
            "             4, 26599,     9,  2182, 25711,  2333,  8131,   561,     4, 20395,\n",
            "         14705,   747,  3511,     7,   489,    50,  2364,    14,  6332,    11,\n",
            "             5,  7040,     4,  1437,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1],\n",
            "        [    0, 37790,  5556,    32, 38889,  1070, 29654,  1672, 38795,     9,\n",
            "             5,  2849, 10337, 44340,   293, 48229,    29, 35423,    48, 43621,\n",
            "         16948,   338, 49066,   642, 35423,  3726,  3999,   118, 43621, 16948,\n",
            "           329,    73, 48999,   176,   742,  2893,   625, 18281,  9316,   424,\n",
            "          1626,     6, 24328,    32, 46065,  7443, 15796,     6,   524,  5107,\n",
            "          6457, 32969, 42428,  2913,    11, 35642, 21423,   203,   101,    97,\n",
            "           453,     9,     5,   333,     4,  1876,  4707,     9, 24328,    33,\n",
            "         40730,    19,   484,    55, 24944,    87,    49, 41771, 22519,     8,\n",
            "          6774,     6, 10298,   106,     7, 26124, 18644,   203,  2514,    87,\n",
            "            49,  3885,    36,   438,  3917,  2617,   449,  3141,   354,   322,\n",
            "           598,  9824,    49,  6787,  3738,     6, 24328,   108, 11153, 16976,\n",
            "            36, 16918,    25, 33473,    43,  2082,    65,    11,   760,     9,\n",
            "             5,    97,  1386,     9,   526,    30,   526,     6,     8,   144,\n",
            "           129,    33,    65, 12628, 10665,     4,   993,  4707,  7615,    10,\n",
            "         38346,   821,  8602,   459,    19,    10,  1763,     9, 15203,  1023,\n",
            "          2617, 41082,    15,  1169,   526,     9,     5, 42771, 11893,     4,\n",
            "           226, 39700,    33, 12672, 12236, 38889,   877,  3738,   396, 24568,\n",
            "            50,    19,  8908,  2906, 24568,    23,   513, 10328,    12,  9579,\n",
            "           498,  1241, 25111, 13907, 10795,     6,   981,     7,   171,   516,\n",
            "          3443,     9,  2985,  1672,   784, 39700, 31274,   246,   742,  1216,\n",
            "         25371, 24328,     6,    53,   484,  1537,  1134,     9,  2985,  1672,\n",
            "           784, 39700,    33, 26635,  7823,     8,  6731, 12137,     6,    61,\n",
            "         24328,  1762,     6,  1712,    42,  2178,    16,    45, 10547,    36,\n",
            "          7048,  1918, 42377,  3178,   225,   493,     6,   211,  1452,   424,\n",
            "         46780,     6,     8, 19972,   571,  1517,  1630, 46780,   322, 10427,\n",
            "         24328,    32,   303,    15,   358,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure that the model and all of its inputs are on the same device.\n",
        "# This is necessary since PyTorch cannot perform operations between matrices that are different devices\n",
        "input_ids = tkr_out[\"input_ids\"].to(device)\n",
        "attn_mask = tkr_out[\"attention_mask\"].to(device)"
      ],
      "metadata": {
        "id": "DXs5p93hdpzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Once we have processed the raw input, we can query the model to generate a summary by using the '.generate()' method\n",
        "# Generation doc: https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\n",
        "output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attn_mask,\n",
        "    max_new_tokens=100\n",
        ")"
      ],
      "metadata": {
        "id": "jsMn_ta5j6uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The .generate() method returns a tokenized output which needs to be decoded back to text\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vsjZd3lkfV_",
        "outputId": "f774eb60-4e00-4e1d-b537-0c77b8fe3a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    2,     0,   133, 23921,    36,   510,   927,  1843,   102,   326,\n",
            "          1023,  4663,    43,    16,    10,   739,  4758,     8,    10,   919,\n",
            "             9,     5, 44878, 15148,   102,  3763,     7,  1817,     4,    85,\n",
            "            34,    10,  2247,     6, 26163,   809,    19,    10,   739,   471,\n",
            "             8, 40844,     6,    10,   251,  7886,     8,  8978, 15503,    19,\n",
            "           909,     6,  2260, 12194, 26224,     4,    85,    16, 10341,  8967,\n",
            "            88,  1117,   485,  2849, 42826,     6,   600,   103, 11865,   129,\n",
            "            80,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1],\n",
            "        [    2,     0,   133, 15587,    36,   510,   927,  1843,   102,  2084,\n",
            "           139,    43,    16,    10,   739,  4758,     9,     5, 44878, 15148,\n",
            "           102,     6,   855,  6272,   129,    11,  4052,    12, 27692,  1327,\n",
            "             8,   666,     4,    85,    34,    10, 26163,     6,  4007,    12,\n",
            "          2871, 16460,   809,   131,    10,   765,     6, 14439,   471,   131,\n",
            "          1062, 12137,   131,     8,    10,  2933,     6, 42175, 13145,  2543,\n",
            "            23,     5,  4767,     9,    63,  7886,     4,    85,    16,  5912,\n",
            "         14548, 31724,   636,   131,  4194,  2943, 25711,    32,  2514,    87,\n",
            "         16856,     8,    33,    10,    55,  5395,   313,   242,     4,     2],\n",
            "        [    2,     0, 37790,  5556,    32, 46065,  7443, 15796,     6,   524,\n",
            "          5107,  6457, 32969, 42428,  2913,    11, 35642, 21423,     4,  1876,\n",
            "          4707,     9, 24328,    33, 40730,    19,   484,    55, 24944,    87,\n",
            "            49, 41771, 22519,     8,  6774,     4,   598,  9824,    49,  6787,\n",
            "          3738,     6, 24328,   108, 11153, 16976,    36, 16918,    25, 33473,\n",
            "            43,  2082,    65,    11,   760,     9,     5,    97,  1386,     9,\n",
            "           526,    30,   526,     4,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the tokenizer for this decoding process\n",
        "# Important: When decoding a batched output, you must use .batch_decode(). Otherwise, use .decode()\n",
        "tkr.batch_decode(output, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmHUljLelSWj",
        "outputId": "44499da8-a51d-439a-d1bb-0b892ea3fdcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The tiger (Panthera tigris) is a large cat and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two.',\n",
              " 'The lion (Panthera leo) is a large cat of the genus Panthera, currently ranging only in Sub-Saharan Africa and India. It has a muscular, broad-chested body; a short, rounded head; round ears; and a dark, hairy tuft at the tip of its tail. It is sexually dimorphic; adult male lions are larger than females and have a more prominent mane.',\n",
              " \"Snakes are ectothermic, amniote vertebrates covered in overlapping scales. Many species of snakes have skulls with several more joints than their lizard ancestors and relatives. To accommodate their narrow bodies, snakes' paired organs (such as kidneys) appear one in front of the other instead of side by side.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation/Decoding Strategies\n",
        "Decoding strategies doc: https://huggingface.co/docs/transformers/en/generation_strategies\n",
        "\n",
        "Sampling strategies doc: https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig\n",
        "- Greedy Decoding\n",
        "- Beam Search\n",
        "- Top-K Sampling\n",
        "- Nucleus Sampling (AKA: Top-P Sampling)\n"
      ],
      "metadata": {
        "id": "tUDJwa-psVpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Greedy Decoding (Default) - At each step, choose the token with the highest probability as the generated token\n",
        "greedy_output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attn_mask,\n",
        "    max_new_tokens=100\n",
        ")\n",
        "tkr.batch_decode(greedy_output, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v53vutKUpiAW",
        "outputId": "7190f8b4-69c7-4e41-8ee0-2ebe5694fb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The tiger (Panthera tigris) is a large cat and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two.',\n",
              " 'The lion (Panthera leo) is a large cat of the genus Panthera, currently ranging only in Sub-Saharan Africa and India. It has a muscular, broad-chested body; a short, rounded head; round ears; and a dark, hairy tuft at the tip of its tail. It is sexually dimorphic; adult male lions are larger than females and have a more prominent mane.',\n",
              " \"Snakes are ectothermic, amniote vertebrates covered in overlapping scales. Many species of snakes have skulls with several more joints than their lizard ancestors and relatives. To accommodate their narrow bodies, snakes' paired organs (such as kidneys) appear one in front of the other instead of side by side.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Beam search - Several sequences (beams) are generated and the sequence with the maximum overall probability is selected\n",
        "beam_output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attn_mask,\n",
        "    max_new_tokens=100,\n",
        "    num_beams=5 #By default, this is set to 1, making it the same as greedy decoding\n",
        ")\n",
        "tkr.batch_decode(beam_output, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1yii5rNGAPk",
        "outputId": "d19941ca-3d36-463c-8ea0-dc7b82c93d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The tiger (Panthera tigris) is a large cat and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two subspecies.',\n",
              " 'The lion (Panthera leo) is a large cat of the genus Panthera. It has a muscular, broad-chested body; a short, rounded head; round ears; and a dark, hairy tuft at the tip of its tail. Adult male lions are larger than females and have a more prominent mane that usually obscures the ears and extends to the shoulders.',\n",
              " \"Snakes are ectothermic, amniote vertebrates covered in overlapping scales. Many species of snakes have skulls with several more joints than their lizard ancestors and relatives. To accommodate their narrow bodies, snakes' paired organs (such as kidneys) appear one in front of the other instead of side by side.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-K Sampling - K highest probability tokens are considered at each step\n",
        "topk_output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attn_mask,\n",
        "    max_new_tokens=100,\n",
        "    do_sample=True, #Whenever a sampling technique is used, do_sample must be set to True\n",
        "    top_k=50 # Number of highest probability tokens to consider\n",
        ")\n",
        "tkr.batch_decode(topk_output, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vieRH5ChGrXz",
        "outputId": "70826185-290c-4b55-a552-1bb5ee2b9adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The tiger (Panthera tigris) is a large cat and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two subspecies.',\n",
              " 'The lion (Panthera leo) is a large cat of the genus Panthera. It has a muscular, broad-chested body; a short, rounded head; round ears; and a dark, hairy tuft at the tip of its tail. Adult male lions are larger than females and have a more prominent mane that usually obscures the ears and extends to the shoulders.',\n",
              " \"Snakes are ectothermic, amniote vertebrates covered in overlapping scales. Many species of snakes have skulls with several more joints than their lizard ancestors and relatives, enabling them to swallow prey much larger than their heads. To accommodate their narrow bodies, snakes' paired organs appear one in front of the other instead of side by side.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nucleus Sampling (AKA: Top-p Sampling) - The smallest set of tokens whose probabilities add up to p (or more) is considered\n",
        "nucleus_output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attn_mask,\n",
        "    max_new_tokens=100,\n",
        "    do_sample=True,\n",
        "    top_p=0.8\n",
        ")\n",
        "tkr.batch_decode(nucleus_output, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQCK2Dj3Hnl0",
        "outputId": "4439d0f9-3c71-4b16-cb6c-afcfdbfb99a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The tiger (Panthera tigris) is a large cat and a member of the genus Panthera native to Asia. It has a powerful, muscular body with a large head and paws, a long tail and orange fur with black, mostly vertical stripes. It is traditionally classified into nine recent subspecies, though some recognise only two subspecies.',\n",
              " 'The lion (Panthera leo) is a large cat of the genus Panthera, currently ranging only in Sub-Saharan Africa and India. It has a muscular, broad-chested body; a short, rounded head; round ears; and a dark, hairy tuft at the tip of its tail. It is sexually dimorphic; adult male lions are larger than females and have a more prominent mane.',\n",
              " \"Snakes are ectothermic, amniote vertebrates covered in overlapping scales. Many species of snakes have skulls with several more joints than their lizard ancestors and relatives. To accommodate their narrow bodies, snakes' paired organs (such as kidneys) appear one in front of the other instead of side by side.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus 1: Seq2Seq with Attention"
      ],
      "metadata": {
        "id": "wgHVX1r_p0Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to tokenize a given list of sentences\n",
        "def encode_batch(sentences):\n",
        "    tokens = tokenizer(\n",
        "        sentences,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return tokens['input_ids'].to(device)\n",
        "\n",
        "src = encode_batch(texts)\n",
        "trg = encode_batch(summaries)"
      ],
      "metadata": {
        "id": "sq-tFCm2p13L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining an Encoder\n",
        "# nn.Module doc: https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer - https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
        "\n",
        "        # Define LSTM - https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # Get embeddings for input tokens\n",
        "        embedded = self.embedding(src)\n",
        "\n",
        "        #Pass embeddings through LSTM to get hidden and cell states\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "# Defining a Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        # Similar to encoder, except there is a language modeling head (linear projection layer) at the end of it\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers, batch_first=True)\n",
        "\n",
        "        # Attention layer\n",
        "        # Doc: (https://docs.pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.htmlhttps://docs.pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=hid_dim, num_heads=4, batch_first=True)\n",
        "\n",
        "        # Language model head - linear layer that projects the hid_dim dimension to vocab_size\n",
        "        self.fc_out = nn.Linear(2*hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        # One forward step of the decoder (similar to encoder)\n",
        "        input = input.unsqueeze(1)  # [batch_size, 1]\n",
        "        embedded = self.embedding(input)\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "\n",
        "        # Apply attention (query=lstm_out, key=value=encoder_outputs)\n",
        "        # Query -> What you're currently trying to understand (current decoder state)\n",
        "        # Key -> Every encoder state to match the current decoder state to\n",
        "        # Value -> Every encoder state using which a weighted sum is computed\n",
        "        attn_out, attn_weights = self.attention(\n",
        "            query=lstm_out, key=encoder_outputs, value=encoder_outputs\n",
        "        )\n",
        "\n",
        "        # Concatenate LSTM output and attention output\n",
        "        combined = torch.cat((lstm_out, attn_out), dim=-1)\n",
        "\n",
        "        # Project the LSTM output into logits (from which individual token probabilities can be computed)\n",
        "        logits = self.fc_out(combined.squeeze(1))\n",
        "        return logits, hidden, cell, attn_weights\n",
        "\n",
        "# Combining encoder and decoder into a Seq2Seq Model\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        batch_size, trg_len = trg.shape\n",
        "\n",
        "        # Initializing a tensor which we will use to store the output vectors computed at each decoding step\n",
        "        outputs = torch.zeros(batch_size, trg_len, VOCAB_SIZE).to(device)\n",
        "\n",
        "        # We get the hidden and cell states from the encoder\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        # Now, we want the decoder to start generating the summary\n",
        "        # So, we pass the first target token (<bos> token)\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # For the current input token, run it through the decoder for one step and get the updated hidden and cell states\n",
        "            output, hidden, cell, attn_weights = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "\n",
        "            # Save the output (logits) for later use\n",
        "            outputs[:, t] = output\n",
        "\n",
        "            # The input for the next step of decoding is set to the CURRENT highest probability token\n",
        "            # Doc: https://docs.pytorch.org/docs/stable/generated/torch.Tensor.argmax.html\n",
        "            input = output.argmax(1)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "JSJZskJVp13M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing our Seq2Seq model\n",
        "enc = Encoder(VOCAB_SIZE, EMB_DIM, HID_DIM, NUM_LAYERS)\n",
        "dec = Decoder(VOCAB_SIZE, EMB_DIM, HID_DIM, NUM_LAYERS)\n",
        "model = Seq2Seq(enc, dec).to(device)\n",
        "\n",
        "# Defining optimizer and loss function for training\n",
        "# Adam optimizer doc: https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
        "# CE Loss doc: https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "# Training loop (tiny demo)\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    # This zeroes-out the gradients computed at the previous step\n",
        "    # Doc: https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Getting an output from the model\n",
        "    output = model(src, trg) # Tensor of size [batch_size, trg_len, vocab_size]\n",
        "\n",
        "    # Now, we compute the CE-loss between the predicted output logits and the ground-truth target tokens\n",
        "    output = output.reshape(-1, VOCAB_SIZE)\n",
        "    trg_y = trg.reshape(-1)\n",
        "    loss = criterion(output, trg_y)\n",
        "\n",
        "    # Computes gradients for one step of backward propagation\n",
        "    # Doc: https://docs.pytorch.org/docs/stable/generated/torch.Tensor.backward.html\n",
        "    loss.backward()\n",
        "\n",
        "    # Updates model weights based on computed gradients\n",
        "    # Doc: https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Inference\n",
        "def summarize(sentence, max_len=MAX_LEN):\n",
        "\n",
        "    # Sets the model to evaluation model (no weight updates will happen)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Tokenize the given sentence and pass it through the model encoder\n",
        "        src = encode_batch([sentence])\n",
        "        encoder_outputs, hidden, cell = model.encoder(src)\n",
        "        input = torch.tensor([SOS_IDX]).to(device) # Input passed to decoder\n",
        "        summary = [input.item()] # Tokens of summary\n",
        "\n",
        "        for _ in range(max_len):\n",
        "\n",
        "            # Get the decoder's output for the current input\n",
        "            output, hidden, cell, attn_weights = model.decoder(input, hidden, cell, encoder_outputs)\n",
        "\n",
        "            # The predicted token is that which has the highest probability\n",
        "            pred = output.argmax(1)\n",
        "\n",
        "            # If the model predicts an End-of-Sentence or Padding Token, we stop generating further\n",
        "            token_id = pred.item()\n",
        "            if token_id == EOS_IDX or token_id == PAD_IDX:\n",
        "                break\n",
        "\n",
        "            # Otherwise, we append the generated token to our summary\n",
        "            summary.append(token_id)\n",
        "\n",
        "            # Input for next step is the token predicted during the current step (autoregressive)\n",
        "            input = pred\n",
        "\n",
        "        # Use the tokenizer to decoder (\"de-tokenize\") the summary\n",
        "        return tokenizer.decode(summary, skip_special_tokens=True)\n",
        "\n",
        "# Generating summaries\n",
        "print(\"\\nSample Summaries:\")\n",
        "for text in texts:\n",
        "    print(f\"TEXT: {text}\")\n",
        "    print(f\"SUMMARY: {summarize(text)}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c6d060-3700-4f2b-9fdd-92c49ac11232",
        "id": "DEAb1Bs2p13N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 10.3361\n",
            "Epoch 2/10, Loss: 10.2277\n",
            "Epoch 3/10, Loss: 9.9682\n",
            "Epoch 4/10, Loss: 9.2848\n",
            "Epoch 5/10, Loss: 7.4120\n",
            "Epoch 6/10, Loss: 5.2189\n",
            "Epoch 7/10, Loss: 4.4365\n",
            "Epoch 8/10, Loss: 3.7568\n",
            "Epoch 9/10, Loss: 3.7476\n",
            "Epoch 10/10, Loss: 3.6522\n",
            "\n",
            "Sample Summaries:\n",
            "TEXT: The cat sat on the mat and looked at the dog.\n",
            "SUMMARY: cat and and mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat mat\n",
            "--------------------------------------------------\n",
            "TEXT: The stock market crashed due to inflation concerns.\n",
            "SUMMARY: market crashed from from from from from from from from from from from from from from from from from from from from from from from from from from from from\n",
            "--------------------------------------------------\n",
            "TEXT: Artificial intelligence is transforming many industries.\n",
            "SUMMARY: market changing industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries industries\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus 2: Writing/Reading Text To/From A File  "
      ],
      "metadata": {
        "id": "m-o5lOdoKHOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, I am writing some articles to a file called 'articles.txt'\n",
        "# Doc: https://docs.python.org/3/library/functions.html#open\n",
        "with open(\"articles.txt\", \"w\") as f:\n",
        "  articles = [\n",
        "      \"Owls are birds from the order Strigiformes[1] (/ˈstrɪdʒəfɔːrmiːz/), which includes over 200 species of mostly solitary and nocturnal birds of prey typified by an upright stance, a large, broad head, binocular vision, binaural hearing, sharp talons, and feathers adapted for silent flight. Exceptions include the diurnal northern hawk-owl and the gregarious burrowing owl. Owls are divided into two families: the true (or typical) owl family, Strigidae, and the barn owl and bay owl family, Tytonidae.[2] Owls hunt mostly small mammals, insects, and other birds, although a few species specialize in hunting fish. They are found in all regions of the Earth except the polar ice caps and some remote islands. A group of owls is called a 'parliament'.[3]\",\n",
        "      \"A frog is any member of a diverse and largely semiaquatic group of short-bodied, tailless amphibian vertebrates composing the order Anura[1] (coming from the Ancient Greek ἀνούρα, literally 'without tail'). Frog species with rough skin texture due to wart-like parotoid glands tend to be called toads, but the distinction between frogs and toads is informal and purely cosmetic, not from taxonomy or evolutionary history. Frogs are widely distributed, ranging from the tropics to subarctic regions, but the greatest concentration of species diversity is in tropical rainforest and associated wetlands. They account for around 88% of extant amphibian species, and are one of the five most diverse vertebrate orders. The oldest fossil \\\"proto-frog\\\" Triadobatrachus is known from the Early Triassic of Madagascar (250 million years ago), but molecular clock dating suggests their divergence from other amphibians may extend further back to the Permian, 265 million years ago. Adult frogs have a stout body, protruding eyes, anteriorly-attached tongue, limbs folded underneath, and no tail (the \\\"tail\\\" of tailed frogs is an extension of the male cloaca). Frogs have glandular skin, with secretions ranging from distasteful to toxic. Their skin varies in colour from well-camouflaged dappled brown, grey and green, to vivid patterns of bright red or yellow and black to show toxicity and ward off predators. Adult frogs live in both fresh water and on dry land; some species are adapted for living underground or in trees. As their skin is semi-permeable, making them susceptible to dehydration, they either live in moist niches or have special adaptations to deal with drier habitats. Frogs produce a wide range of vocalisations, particularly in their breeding season, and exhibit many different kinds of complex behaviors to attract mates, to fend off predators and to generally survive. Being oviparous anamniotes, frogs typically spawn their eggs in bodies of water. The eggs then hatch into fully aquatic larvae called tadpoles, which have tails and internal gills. A few species lay eggs on land or bypass the tadpole stage altogether. Tadpoles have highly specialised rasping mouth parts suitable for herbivorous, omnivorous or planktivorous diets. The life cycle is completed when they metamorphose into semiaquatic adults capable of terrestrial locomotion and hybrid respiration using both lungs aided by buccal pumping and gas exchange across the skin, and the larval tail regresses into an internal urostyle. Adult frogs generally have a carnivorous diet consisting of small invertebrates, especially insects, but omnivorous species exist and a few feed on plant matter. Frogs generally seize and ingest food by protruding their adhesive tongue and then swallow the item whole, often using their eyeballs and extraocular muscles to help pushing down the throat, and their digestive system is extremely efficient at converting what they eat into body mass. Being low-level consumers, both tadpoles and adult frogs are an important food source for other predators and a vital part of the food web dynamics of many of the world's ecosystems.\",\n",
        "      \"The meerkat (Suricata suricatta) or suricate is a small mongoose found in southern Africa. It is characterised by a broad head, large eyes, a pointed snout, long legs, a thin tapering tail, and a brindled coat pattern. The head-and-body length is around 24–35 cm (9.4–13.8 in), and the weight is typically between 0.62 and 0.97 kg (1.4 and 2.1 lb). The coat is light grey to yellowish-brown with alternate, poorly defined light and dark bands on the back. Meerkats have foreclaws adapted for digging and have the ability to thermoregulate to survive in their harsh, dry habitat. Three subspecies are recognised. Meerkats are highly social, and form packs of two to 30 individuals each that occupy home ranges around 5 km2 (1.9 sq mi) in area. There is a social hierarchy—generally dominant individuals in a pack breed and produce offspring, and the nonbreeding, subordinate members provide altruistic care to the pups. Breeding occurs around the year, with peaks during heavy rainfall; after a gestation of 60 to 70 days, a litter of three to seven pups is born. They live in rock crevices in stony, often calcareous areas, and in large burrow systems in plains. The burrow systems, typically 5 m (16 ft) in diameter with around 15 openings, are large underground networks consisting of two to three levels of tunnels. These tunnels are around 7.5 cm (3.0 in) high at the top and wider below, and extend up to 1.5 m (5 ft) into the ground. Burrows have moderated internal temperatures and provide a comfortable microclimate that protects meerkats in harsh weather and at extreme temperatures. \"\n",
        "  ]\n",
        "\n",
        "  for a in articles:\n",
        "    # Write article to the file followed by a newline (\\n) so that each line in the file corresponds to a unique article\n",
        "    f.write(a)\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "wio19qa9KLmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"articles.txt\", \"r\") as f:\n",
        "  file_txt = f.readlines()\n",
        "\n",
        "file_txt[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "lIaHXDNjKiAh",
        "outputId": "62241c4c-4c86-4b79-f2d1-362302f0db69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Owls are birds from the order Strigiformes[1] (/ˈstrɪdʒəfɔːrmiːz/), which includes over 200 species of mostly solitary and nocturnal birds of prey typified by an upright stance, a large, broad head, binocular vision, binaural hearing, sharp talons, and feathers adapted for silent flight. Exceptions include the diurnal northern hawk-owl and the gregarious burrowing owl. Owls are divided into two families: the true (or typical) owl family, Strigidae, and the barn owl and bay owl family, Tytonidae.[2] Owls hunt mostly small mammals, insects, and other birds, although a few species specialize in hunting fish. They are found in all regions of the Earth except the polar ice caps and some remote islands. A group of owls is called a 'parliament'.[3]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}