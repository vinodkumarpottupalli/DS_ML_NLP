{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tikGNaDCNGbQ"
      },
      "source": [
        "# Importing Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u5R1rCUWNL4A"
      },
      "outputs": [],
      "source": [
        "!pip install -q gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "terYuMJuNB-N"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapi\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1QYKlOzNWG7"
      },
      "source": [
        "# One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLLDEVWkNfm0"
      },
      "outputs": [],
      "source": [
        "#Defining a vocabulary of words for one-hot encoding\n",
        "VOCAB = [\"cat\", \"dog\", \"car\", \"bus\", \"train\"]\n",
        "VOCAB_SIZE = len(VOCAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIu7yQC-Npws",
        "outputId": "450f5d8d-4087-4865-f5a4-9090826ca093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID of 'cat' is 0\n",
            "ID of 'dog' is 1\n",
            "ID of 'car' is 2\n",
            "ID of 'bus' is 3\n",
            "ID of 'train' is 4\n"
          ]
        }
      ],
      "source": [
        "#Create a dictionary which stores a unique integer ID for each word\n",
        "word_to_index = {}\n",
        "id = 0 #First word gets an ID of 0\n",
        "\n",
        "for word in VOCAB:\n",
        "\n",
        "    #Assign ID to word\n",
        "    word_to_index[word] = id\n",
        "    print(f\"ID of '{word}' is {word_to_index[word]}\")\n",
        "\n",
        "    # Increment ID for the next word\n",
        "    id += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBif-uslOVR7",
        "outputId": "1fdefb60-369d-4787-a1d3-f57fcfeadabf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-hot encoded representation for 'cat' is tensor([[1., 0., 0., 0., 0.]])\n",
            "One-hot encoded representation for 'dog' is tensor([[0., 1., 0., 0., 0.]])\n",
            "One-hot encoded representation for 'car' is tensor([[0., 0., 1., 0., 0.]])\n",
            "One-hot encoded representation for 'bus' is tensor([[0., 0., 0., 1., 0.]])\n",
            "One-hot encoded representation for 'train' is tensor([[0., 0., 0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Creating a one-hot encoded vector for each word\n",
        "vectors_onehot = {} #Dictionary to store one-hot encoded representation\n",
        "\n",
        "for word in VOCAB:\n",
        "    #Create a vector of size VOCAB_SIZE with all elements set to 0\n",
        "    vec = torch.zeros(VOCAB_SIZE)\n",
        "\n",
        "    #Get the word's integer ID and set the vector component at that index equal to 1, rest remain equal to 0\n",
        "    #Eg: For a word with ID = 0, its one-hot encoded representation should be [1, 0, 0, 0, 0] (assuming 5 words in vocab)\n",
        "    word_id = word_to_index[word]\n",
        "    vec[word_id] = 1.0\n",
        "\n",
        "    #Store one-hot encoded vector to dictionary\n",
        "    vectors_onehot[word] = vec.view(1, -1)\n",
        "\n",
        "    #View one-hot encoded vectors\n",
        "    print(f\"One-hot encoded representation for '{word}' is {vectors_onehot[word]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex0koYJLQRMS"
      },
      "source": [
        "# Word2Vec Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WBynKvWQWP7"
      },
      "outputs": [],
      "source": [
        "#Defining a set of sentences for our Word2Vec model to learn representations from\n",
        "SENTENCES = [\n",
        "    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n",
        "    [\"a\", \"cat\", \"is\", \"a\", \"pet\"],\n",
        "    [\"dogs\", \"and\", \"cats\", \"are\", \"animals\"],\n",
        "    [\"the\", \"bus\", \"stopped\", \"at\", \"the\", \"station\"],\n",
        "    [\"a\", \"train\", \"carries\", \"many\", \"passengers\"],\n",
        "    [\"cars\", \"and\", \"buses\", \"are\", \"used\", \"for\", \"transport\"],\n",
        "    [\"the\", \"dog\", \"ran\", \"beside\", \"the\", \"car\"],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmYm2fRGQhaS"
      },
      "outputs": [],
      "source": [
        "#Create a Word2Vec model and train it to learn representations using SENTENCES\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=SENTENCES, #List of sentences to learn from\n",
        "    vector_size=10, #Size of the embedding vectors\n",
        "    min_count=1, #Ignores words with frequency less than min_count\n",
        "    sg=1 #Uses skip-gram training algorithm (replace with 0 to use CBOW)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfNwa44jR1u2",
        "outputId": "63669031-486d-4a4b-aae4-5561208fa9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec representation for 'cat' is tensor([[-0.0960,  0.0501, -0.0876, -0.0439, -0.0004, -0.0030, -0.0766,  0.0961,\n",
            "          0.0498,  0.0923]])\n",
            "Word2Vec representation for 'dog' is tensor([[-0.0816,  0.0449, -0.0413,  0.0082,  0.0851, -0.0446,  0.0451, -0.0679,\n",
            "         -0.0355,  0.0940]])\n",
            "Word2Vec representation for 'car' is tensor([[-0.0158,  0.0032, -0.0414, -0.0769, -0.0149,  0.0247, -0.0090,  0.0553,\n",
            "         -0.0274,  0.0227]])\n",
            "Word2Vec representation for 'bus' is tensor([[-0.0464, -0.0316,  0.0931,  0.0087,  0.0749, -0.0607,  0.0516,  0.0992,\n",
            "         -0.0846, -0.0514]])\n",
            "Word2Vec representation for 'train' is tensor([[-0.0371, -0.0875,  0.0544,  0.0651, -0.0079, -0.0671, -0.0709, -0.0250,\n",
            "          0.0514, -0.0367]])\n"
          ]
        }
      ],
      "source": [
        "#Dictionary to store word2vec representations of each word\n",
        "vectors_w2v = {}\n",
        "for word in VOCAB:\n",
        "    vectors_w2v[word] = torch.tensor(w2v_model.wv[word]).view(1, -1)\n",
        "    print(f\"Word2Vec representation for '{word}' is {vectors_w2v[word]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ac0xOJYXNV"
      },
      "source": [
        "# GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCiRoY0WYW32"
      },
      "outputs": [],
      "source": [
        "#Load a pre-trained GloVe model\n",
        "glove = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy9J68XDYtHV",
        "outputId": "e96a4a99-1a13-478c-ee46-38cd683a38e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GloVe representation for 'cat' is tensor([[ 0.4528, -0.5011, -0.5371, -0.0157,  0.2219,  0.5460, -0.6730, -0.6891,\n",
            "          0.6349, -0.1973,  0.3368,  0.7735,  0.9009,  0.3849,  0.3837,  0.2657,\n",
            "         -0.0806,  0.6109, -1.2894, -0.2231, -0.6158,  0.2170,  0.3561,  0.4450,\n",
            "          0.6089, -1.1633, -1.1579,  0.3612,  0.1047, -0.7832,  1.4352,  0.1863,\n",
            "         -0.2611,  0.8328, -0.2312,  0.3248,  0.1449, -0.4455,  0.3350, -0.9595,\n",
            "         -0.0975,  0.4814, -0.4335,  0.6945,  0.9104, -0.2817,  0.4164, -1.2609,\n",
            "          0.7128,  0.2378]])\n",
            "GloVe representation for 'dog' is tensor([[ 0.1101, -0.3878, -0.5762, -0.2771,  0.7052,  0.5399, -1.0786, -0.4015,\n",
            "          1.1504, -0.5678,  0.0039,  0.5288,  0.6456,  0.4726,  0.4855, -0.1841,\n",
            "          0.1801,  0.9140, -1.1979, -0.5778, -0.3799,  0.3361,  0.7720,  0.7556,\n",
            "          0.4551, -1.7671, -1.0503,  0.4257,  0.4189, -0.6833,  1.5673,  0.2768,\n",
            "         -0.6171,  0.6464, -0.0770,  0.3712,  0.1308, -0.4514,  0.2540, -0.7439,\n",
            "         -0.0862,  0.2407, -0.6482,  0.8355,  1.2502, -0.5138,  0.0422, -0.8812,\n",
            "          0.7158,  0.3852]])\n",
            "GloVe representation for 'car' is tensor([[ 0.4769, -0.0846,  1.4641,  0.0470,  0.1469,  0.5082, -1.2228, -0.2261,\n",
            "          0.1931, -0.2976,  0.2060, -0.7128, -1.6288,  0.1710,  0.7480, -0.0619,\n",
            "         -0.6577,  1.3786, -0.6804, -1.7551,  0.5832,  0.2516, -1.2114,  0.8134,\n",
            "          0.0948, -1.6819, -0.6450,  0.6322,  1.1211,  0.1611,  2.5379,  0.2485,\n",
            "         -0.2682,  0.3282,  1.2916,  0.2355,  0.6147, -0.1344, -0.1324,  0.2740,\n",
            "         -0.1182,  0.1354,  0.0743, -0.6195,  0.4547, -0.3032, -0.2188, -0.5605,\n",
            "          1.1177, -0.3659]])\n",
            "GloVe representation for 'bus' is tensor([[ 0.8477,  0.0703,  0.9679, -0.2716, -0.3762,  0.3198, -1.3108,  0.0911,\n",
            "          0.5992, -0.9022, -0.0509, -0.8389, -0.6160,  0.2964, -0.4219, -0.2197,\n",
            "         -0.9401,  1.2221, -0.6653, -0.5774,  0.7613,  0.5146, -0.8856,  1.5135,\n",
            "          0.4233, -1.2947,  0.4552,  0.6707,  0.8019, -0.6545,  2.4117,  0.6245,\n",
            "         -0.0466,  0.3752,  1.0103,  0.2526,  1.0913, -0.7943, -0.1703,  1.4866,\n",
            "         -0.2408,  0.0219, -0.0160, -0.4432, -0.1391,  0.0133, -0.4943, -0.5770,\n",
            "          1.1997, -0.3971]])\n",
            "GloVe representation for 'train' is tensor([[ 0.9497,  0.3433,  0.8450, -0.8852, -0.7208, -0.2931, -0.7468,  0.6512,\n",
            "          0.4730, -0.7401,  0.1877, -0.3828, -0.5590,  0.4295, -0.2698, -0.4238,\n",
            "         -0.3124,  1.3423, -0.7857, -0.6302,  0.9182,  0.2113, -0.5744,  1.4549,\n",
            "          0.7546, -1.6165, -0.0085,  0.0029,  0.5130, -0.4745,  2.5306,  0.8594,\n",
            "         -0.3067,  0.0578,  0.6623,  0.2080,  0.6424, -0.5246, -0.0534,  1.1404,\n",
            "         -0.1370, -0.1836,  0.4546, -0.5096, -0.0255, -0.0286,  0.1805, -0.4483,\n",
            "          0.4053, -0.3682]])\n"
          ]
        }
      ],
      "source": [
        "#Dictionary to store GloVe representations of each word\n",
        "vectors_glove = {}\n",
        "\n",
        "#Get the GloVe embedding for each word and store it in the dictionary\n",
        "for word in VOCAB:\n",
        "  vectors_glove[word] = torch.tensor(glove[word]).view(1, -1)\n",
        "  print(f\"GloVe representation for '{word}' is {vectors_glove[word]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjsK9cFQZYvV"
      },
      "source": [
        "# Evaluation of Representations (Cosine Similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2jnu6lvZcmY"
      },
      "outputs": [],
      "source": [
        "#Defining pairs of words whose embeddings we will compare (evaluate) with respect to each other\n",
        "pairs = [\n",
        "  # Animal v/s animal\n",
        "  (\"cat\", \"dog\"),\n",
        "\n",
        "  # Animal v/s vehicle\n",
        "  (\"cat\", \"car\"),\n",
        "  (\"cat\", \"bus\"),\n",
        "  (\"cat\", \"train\"),\n",
        "  (\"dog\", \"car\"),\n",
        "  (\"dog\", \"bus\"),\n",
        "  (\"dog\", \"train\"),\n",
        "\n",
        "  # Vehicle v/s vehicle\n",
        "  (\"car\", \"bus\"),\n",
        "  (\"car\", \"train\"),\n",
        "  (\"bus\", \"train\"),\n",
        "\n",
        "  # Word compared to itself\n",
        "  (\"cat\", \"cat\"),\n",
        "  (\"dog\", \"dog\"),\n",
        "  (\"car\", \"car\"),\n",
        "  (\"bus\", \"bus\"),\n",
        "  (\"train\", \"train\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVDGI8_bZtm9"
      },
      "outputs": [],
      "source": [
        "#Define a function that evaluates pair-wise similarities given a dictionary of representation vectors\n",
        "def evaluate_similarity(vectors):\n",
        "  for w1, w2 in pairs:\n",
        "    v1 = vectors[w1] #Representation of first word\n",
        "    v2 = vectors[w2] #Representation of second word\n",
        "\n",
        "    #Compute cosine similarity of both vectors and print it out\n",
        "    sim = torch.nn.functional.cosine_similarity(v1, v2).item()\n",
        "    print(f\"s({w1}, {w2}) = {sim:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD16NsX2aHnM"
      },
      "source": [
        "## Evaluating One-Hot Encoded Vectors\n",
        "We see that when a word is compared to itself, its similarity is always 1 (a word is identical to itself).\n",
        "\n",
        "However, it has 0 similarity whenever compared to a different word. This indicates a lack of semantic meaning in one-hot representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PhX2Kf6aKjj",
        "outputId": "4c940898-67db-4cfe-d48b-a113b9a22d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s(cat, dog) = 0.000\n",
            "s(cat, car) = 0.000\n",
            "s(cat, bus) = 0.000\n",
            "s(cat, train) = 0.000\n",
            "s(dog, car) = 0.000\n",
            "s(dog, bus) = 0.000\n",
            "s(dog, train) = 0.000\n",
            "s(car, bus) = 0.000\n",
            "s(car, train) = 0.000\n",
            "s(bus, train) = 0.000\n",
            "s(cat, cat) = 1.000\n",
            "s(dog, dog) = 1.000\n",
            "s(car, car) = 1.000\n",
            "s(bus, bus) = 1.000\n",
            "s(train, train) = 1.000\n"
          ]
        }
      ],
      "source": [
        "evaluate_similarity(vectors_onehot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk0ypL_zalYL"
      },
      "source": [
        "## Evaluating Word2Vec Encoded Vectors\n",
        "Here, different words have non-zero similarities when compared to each other denoting that these representations store some semantic information about words in them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBCdRwkHa1Zc",
        "outputId": "d0cae78e-d24d-485c-d443-008c65d27c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s(cat, dog) = 0.250\n",
            "s(cat, car) = 0.615\n",
            "s(cat, bus) = -0.196\n",
            "s(cat, train) = -0.159\n",
            "s(dog, car) = -0.041\n",
            "s(dog, bus) = 0.036\n",
            "s(dog, train) = -0.212\n",
            "s(car, bus) = -0.014\n",
            "s(car, train) = -0.575\n",
            "s(bus, train) = 0.138\n",
            "s(cat, cat) = 1.000\n",
            "s(dog, dog) = 1.000\n",
            "s(car, car) = 1.000\n",
            "s(bus, bus) = 1.000\n",
            "s(train, train) = 1.000\n"
          ]
        }
      ],
      "source": [
        "evaluate_similarity(vectors_w2v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBMFotoxbED7"
      },
      "source": [
        "## Evaluating GloVe Vectors\n",
        "Here, different words have non-zero similarities when compared to each other and these similarity values even correspond to our intuitive sense of how similar two words might be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpEwS5TAbWXs",
        "outputId": "fbcd0cbc-5854-4779-f0f7-89c0a397cde5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s(cat, dog) = 0.922\n",
            "s(cat, car) = 0.364\n",
            "s(cat, bus) = 0.307\n",
            "s(cat, train) = 0.316\n",
            "s(dog, car) = 0.464\n",
            "s(dog, bus) = 0.406\n",
            "s(dog, train) = 0.418\n",
            "s(car, bus) = 0.821\n",
            "s(car, train) = 0.766\n",
            "s(bus, train) = 0.902\n",
            "s(cat, cat) = 1.000\n",
            "s(dog, dog) = 1.000\n",
            "s(car, car) = 1.000\n",
            "s(bus, bus) = 1.000\n",
            "s(train, train) = 1.000\n"
          ]
        }
      ],
      "source": [
        "evaluate_similarity(vectors_glove)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
