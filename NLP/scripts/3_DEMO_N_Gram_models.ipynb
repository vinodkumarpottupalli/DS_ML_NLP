{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Summary of the Demo: Text Representation and Sentiment Classification**\n",
        "\n",
        "This demo showcases a complete workflow of **text preprocessing, vectorization, and sentiment classification** using the **Bag-of-Words (BoW)** model and **Naive Bayes** classifier ‚Äî two of the most fundamental yet powerful techniques in natural language processing (NLP).\n",
        "\n",
        "The core idea is to demonstrate how raw text data (like movie reviews or taglines) can be transformed into numerical representations that machine learning models can understand, and how enhancing this representation with **n-grams** can significantly impact performance and interpretability.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Purpose and Flow of the Demo**\n",
        "\n",
        "The objective of this demo is to illustrate:\n",
        "\n",
        "* How to **convert unstructured text** into a structured numerical form using BoW.\n",
        "* How to **train and evaluate** a simple machine learning model (Naive Bayes) on text data.\n",
        "* How **n-grams** enhance context understanding by including combinations of words rather than single tokens.\n",
        "* How increasing linguistic complexity (1-gram ‚Üí 3-gram) affects both **accuracy and computational cost**.\n",
        "\n",
        "The workflow follows a clear progression ‚Äî from data loading and cleaning, through feature extraction, to model evaluation and optimization.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Core Components Explained**\n",
        "\n",
        "#### **a. Text Preprocessing**\n",
        "\n",
        "Data cleaning steps like removing missing values, lowercasing text, removing stopwords, and lemmatization are performed.\n",
        "This ensures that the text is consistent and that only meaningful tokens contribute to model learning.\n",
        "\n",
        "Significance:\n",
        "üßπ *Reduces noise and redundancy, ensuring more accurate text representations.*\n",
        "\n",
        "---\n",
        "\n",
        "#### **b. Bag-of-Words Representation**\n",
        "\n",
        "Using `CountVectorizer`, each document (review or tagline) is transformed into a **vector of word counts**.\n",
        "This creates a simple, interpretable numerical matrix where:\n",
        "\n",
        "* Rows = documents\n",
        "* Columns = unique words (features)\n",
        "* Values = frequency of each word\n",
        "\n",
        "Significance:\n",
        "üî¢ *BoW captures word presence and frequency, forming the foundation for all classical NLP models.*\n",
        "\n",
        "---\n",
        "\n",
        "#### **c. Model Training ‚Äî Multinomial Naive Bayes**\n",
        "\n",
        "A **Multinomial Naive Bayes classifier** is trained on the BoW features.\n",
        "It works well for discrete count data and is widely used in text classification because it assumes word independence and calculates class probabilities efficiently.\n",
        "\n",
        "Significance:\n",
        "‚öôÔ∏è *Provides a fast, effective baseline for sentiment prediction and other NLP tasks.*\n",
        "\n",
        "---\n",
        "\n",
        "### **3. The Power of N-Grams**\n",
        "\n",
        "The highlight of the demo is the transition from **unigrams** (single words) to **higher-order n-grams** (word pairs and triplets).\n",
        "\n",
        "* **Unigrams (n=1):** Capture isolated word importance (e.g., ‚Äúgood‚Äù, ‚Äúbad‚Äù).\n",
        "* **Bigrams (n=2):** Capture short context (e.g., ‚Äúnot good‚Äù, ‚Äúvery bad‚Äù).\n",
        "* **Trigrams (n=3):** Capture richer, phrase-level meaning (e.g., ‚Äúa waste of‚Äù, ‚Äúone of the‚Äù).\n",
        "\n",
        "By increasing `ngram_range`, the model begins to recognize **word dependencies and context**, crucial for sentiment analysis. For instance:\n",
        "\n",
        "* A unigram model might see ‚Äúgood‚Äù and predict positive.\n",
        "* A bigram model sees ‚Äúnot good‚Äù and correctly predicts negative.\n",
        "\n",
        "However, as n increases:\n",
        "\n",
        "* **Feature dimensionality explodes** (many more word combinations).\n",
        "* **Computation time rises**, and **memory requirements grow**.\n",
        "\n",
        "The demo quantitatively compares these effects ‚Äî showing how higher-order n-grams can slightly boost accuracy but at the cost of performance and speed.\n",
        "\n",
        "Significance:\n",
        "üß© *N-grams bridge the gap between bag-of-words simplicity and deep contextual understanding, allowing classical ML models to capture limited semantic structure without neural networks.*\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Evaluation and Insights**\n",
        "\n",
        "The demo measures both **accuracy** and **runtime** for unigram and trigram models, revealing an important trade-off:\n",
        "\n",
        "* **Unigram models** ‚Üí Fast, simple, baseline accuracy.\n",
        "* **N-gram models** ‚Üí More accurate but computationally heavier.\n",
        "\n",
        "It also demonstrates how the **number of features** (vocabulary size) grows rapidly with n-gram order ‚Äî emphasizing the importance of balancing context richness with model efficiency.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Broader Takeaways**\n",
        "\n",
        "* **N-gram models** remain highly relevant even in the age of deep learning, especially for smaller datasets or interpretable systems.\n",
        "* **Preprocessing quality** (lemmatization, stopword removal) strongly influences model clarity and feature quality.\n",
        "* **Naive Bayes + n-grams** provides a solid, explainable baseline for text classification tasks like sentiment analysis, spam detection, and topic categorization.\n",
        "\n",
        "---\n",
        "\n",
        "### **In Summary**\n",
        "\n",
        "This demo effectively demonstrates how **linguistic granularity (via n-grams)** impacts a machine learning model‚Äôs ability to understand and predict sentiment.\n",
        "It blends theory with practice ‚Äî showing the trade-offs between **simplicity, interpretability, and contextual depth**.\n",
        "\n",
        "Ultimately, it helps learners grasp how small enhancements in text representation can lead to **significant gains in understanding language nuances**, forming a bridge from traditional NLP to more advanced methods like TF-IDF and word embeddings.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sUjAqc1m3ZB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWfF4J_qQGQr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. What is the purpose of importing `pandas`, `numpy`, and `matplotlib.pyplot`?**\n",
        "\n",
        "**Answer:**\n",
        "These libraries are essential for data analysis and visualization in Python:\n",
        "\n",
        "* **pandas**: Handles data manipulation and analysis (e.g., DataFrames).\n",
        "* **numpy**: Provides numerical operations and array handling.\n",
        "* **matplotlib.pyplot**: Used for plotting graphs and visualizing data.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why do we import `spacy`?**\n",
        "\n",
        "**Answer:**\n",
        "`spaCy` is a natural language processing (NLP) library used for tasks like tokenization, named entity recognition, and part-of-speech tagging. Importing it prepares the environment for text analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. What does `plt.rcParams['figure.figsize'] = (8, 8)` do?**\n",
        "\n",
        "**Answer:**\n",
        "It sets the **default size** for all figures created using Matplotlib to **8 inches by 8 inches**, ensuring consistent and readable plot dimensions across visualizations.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Do we need to install these libraries before using them?**\n",
        "\n",
        "**Answer:**\n",
        "Yes. If not already installed, use the following commands:\n",
        "\n",
        "```bash\n",
        "pip install pandas numpy matplotlib spacy\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Why are all these libraries imported at the beginning?**\n",
        "\n",
        "**Answer:**\n",
        "It‚Äôs a best practice to import all dependencies at the start of the script. This ensures that all necessary packages are loaded and available before the code execution proceeds.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "454yPNHDxGx_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1T66kpkQGQs"
      },
      "source": [
        "## Building a bag of words model\n",
        "- Bag of words model\n",
        "    - Extract word tokens\n",
        "    - Compute frequency of word tokens\n",
        "    - Construct a word vector out of these frequencies and vocabulary of corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WswQ1ai0QGQt"
      },
      "source": [
        "### BoW model for movie taglines\n",
        "In this exercise, you have been provided with a `corpus` of more than 7000 movie tag lines. Your job is to generate the bag of words representation `bow_matrix` for these taglines. For this exercise, we will ignore the text preprocessing step and generate `bow_matrix` directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnHy8MjhQGQt",
        "outputId": "cd86f7be-09d9-45b8-847f-29bd88e4c88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                        title  \\\n",
              "1   8844                      Jumanji   \n",
              "2  15602             Grumpier Old Men   \n",
              "3  31357            Waiting to Exhale   \n",
              "4  11862  Father of the Bride Part II   \n",
              "5    949                         Heat   \n",
              "\n",
              "                                            overview  \\\n",
              "1  When siblings Judy and Peter discover an encha...   \n",
              "2  A family wedding reignites the ancient feud be...   \n",
              "3  Cheated on, mistreated and stepped on, the wom...   \n",
              "4  Just when George Banks has recovered from his ...   \n",
              "5  Obsessive master thief, Neil McCauley leads a ...   \n",
              "\n",
              "                                             tagline  \n",
              "1          roll the dice and unleash the excitement!  \n",
              "2  still yelling. still fighting. still ready for...  \n",
              "3  friends are the people who let you be yourself...  \n",
              "4  just when his world is back to normal... he's ...  \n",
              "5                           a los angeles crime saga  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1448d2d9-6c38-455f-9c30-34f78d35925f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>overview</th>\n",
              "      <th>tagline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8844</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>roll the dice and unleash the excitement!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15602</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>A family wedding reignites the ancient feud be...</td>\n",
              "      <td>still yelling. still fighting. still ready for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31357</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
              "      <td>friends are the people who let you be yourself...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11862</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Just when George Banks has recovered from his ...</td>\n",
              "      <td>just when his world is back to normal... he's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>949</td>\n",
              "      <td>Heat</td>\n",
              "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
              "      <td>a los angeles crime saga</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1448d2d9-6c38-455f-9c30-34f78d35925f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1448d2d9-6c38-455f-9c30-34f78d35925f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1448d2d9-6c38-455f-9c30-34f78d35925f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c850dc02-bb99-40cc-adaf-3c27b4b1021e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c850dc02-bb99-40cc-adaf-3c27b4b1021e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c850dc02-bb99-40cc-adaf-3c27b4b1021e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movies",
              "summary": "{\n  \"name\": \"movies\",\n  \"rows\": 7033,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60599,\n        \"min\": 5,\n        \"max\": 410921,\n        \"num_unique_values\": 7027,\n        \"samples\": [\n          19973,\n          4523,\n          74643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6843,\n        \"samples\": [\n          \"Mallrats\",\n          \"Alfie\",\n          \"Daddy Day Camp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7025,\n        \"samples\": [\n          \"Harry (Brian Petsos) is having a very, very bad day. He returns home from an all-night drinking binge with his cousin Cecil (Oscar Issac), to discover that his little dog Jolly...Harry's one true love and the source of light in his dark, solitary life-has been murdered. Brokenhearted and beyond consolation, he vows to track down the dog's murderer at any cost. Armed with a stockpile of firepower in the trunk of his car, he and Cecil embark on a frenzied, alcohol-fueled wild-goose chase, leaving a bloody path of destruction in their wake.\",\n          \"After proving himself on the field of battle in the French and Indian War, Benjamin Martin wants nothing more to do with such things, preferring the simple life of a farmer. But when his son Gabriel enlists in the army to defend their new nation, America, against the British, Benjamin reluctantly returns to his old life to protect his son.\",\n          \"During the war in Afghanistan a Soviet tank crew commanded by a tyrannical officer find themselves lost and in a struggle against a band of Mujahadeen guerrillas in the mountains.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tagline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7006,\n        \"samples\": [\n          \"seize your glory!\",\n          \"the maddest comics of them all!\",\n          \"flesh to touch... flesh to burn! don't keep the wicker man waiting!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "movies = pd.read_csv('movie_overviews.csv').dropna()\n",
        "movies['tagline'] = movies['tagline'].str.lower()\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TTXeZNLQGQt"
      },
      "outputs": [],
      "source": [
        "corpus = movies['tagline']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz24ROwXQGQu",
        "outputId": "0cd7a607-06fb-424c-d3df-eebc879896af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7033, 6614)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Generate matrix of word vectors\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Print the shape of bow_matrix\n",
        "print(bow_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. What does `pd.read_csv('movie_overviews.csv').dropna()` do?**\n",
        "\n",
        "**Answer:**\n",
        "It reads the CSV file named **`movie_overviews.csv`** into a pandas DataFrame and then removes all rows containing **missing (NaN)** values to ensure clean data before analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why do we convert the ‚Äòtagline‚Äô column to lowercase?**\n",
        "\n",
        "**Answer:**\n",
        "The line\n",
        "\n",
        "```python\n",
        "movies['tagline'] = movies['tagline'].str.lower()\n",
        "```\n",
        "\n",
        "ensures **text normalization**. Converting all taglines to lowercase avoids treating words like *‚ÄúLove‚Äù* and *‚Äúlove‚Äù* as different tokens during text vectorization.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. What is the purpose of `CountVectorizer` here?**\n",
        "\n",
        "**Answer:**\n",
        "`CountVectorizer` converts the text data (taglines) into a **Bag-of-Words (BoW)** representation ‚Äî a numerical matrix where each row represents a movie tagline and each column represents a word, with values showing the frequency of that word.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What does `bow_matrix = vectorizer.fit_transform(corpus)` return?**\n",
        "\n",
        "**Answer:**\n",
        "It returns a **sparse matrix** where:\n",
        "\n",
        "* Rows = individual taglines\n",
        "* Columns = unique words (vocabulary)\n",
        "* Values = frequency counts of each word in each tagline\n",
        "\n",
        "This is the numerical input for many machine learning or NLP models.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. What does `bow_matrix.shape` indicate?**\n",
        "\n",
        "**Answer:**\n",
        "It prints a tuple like `(number_of_taglines, number_of_unique_words)`.\n",
        "For example, `(1000, 5000)` means there are **1000 taglines** and **5000 unique words** in the vocabulary built from them.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l2hWcVlVxjCj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9G5JdyiQGQu"
      },
      "source": [
        "You now know how to generate a bag of words representation for a given corpus of documents. Notice that the word vectors created have more than 6600 dimensions. However, most of these dimensions have a value of zero since most words do not occur in a particular tagline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaKzcIonQGQv"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHpdrUDWQGQv"
      },
      "outputs": [],
      "source": [
        "lem_corpus = corpus.apply(lambda row: ' '.join([t.lemma_ for t in nlp(row)\n",
        "                                                if t.lemma_ not in stopwords\n",
        "                                                and t.lemma_.isalpha()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw4E7V9YQGQv",
        "outputId": "e7783dde-518f-48f1-e6ee-773995196f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1                            roll dice unleash excitement\n",
              "2                                   yell fight ready love\n",
              "3                            friend people let let forget\n",
              "4                              world normal surprise life\n",
              "5                                  los angeles crime saga\n",
              "                              ...                        \n",
              "9091                         kingsglaive final fantasy xv\n",
              "9093                       happen vegas stay vegas happen\n",
              "9095    decorate officer devoted family man defend hon...\n",
              "9097                              god incarnate city doom\n",
              "9098                                      band know story\n",
              "Name: tagline, Length: 7033, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tagline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>roll dice unleash excitement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yell fight ready love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>friend people let let forget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>world normal surprise life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>los angeles crime saga</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9091</th>\n",
              "      <td>kingsglaive final fantasy xv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9093</th>\n",
              "      <td>happen vegas stay vegas happen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9095</th>\n",
              "      <td>decorate officer devoted family man defend hon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9097</th>\n",
              "      <td>god incarnate city doom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9098</th>\n",
              "      <td>band know story</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7033 rows √ó 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "lem_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIe3-bfhQGQv",
        "outputId": "5a505e69-aac6-4399-b3af-7823e462d313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7033, 4946)\n"
          ]
        }
      ],
      "source": [
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Generate of word vectors\n",
        "bow_lem_matrix = vectorizer.fit_transform(lem_corpus)\n",
        "\n",
        "# Print the shape of how_lem_matrix\n",
        "print(bow_lem_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. What does `spacy.load('en_core_web_sm')` do?**\n",
        "\n",
        "**Answer:**\n",
        "It loads **spaCy‚Äôs small English language model**, which provides linguistic features such as tokenization, lemmatization, and part-of-speech tagging. This model is required before processing text with `nlp(row)`.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What is the purpose of `spacy.lang.en.stop_words.STOP_WORDS`?**\n",
        "\n",
        "**Answer:**\n",
        "This loads a set of **English stopwords** (common words like *‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúand‚Äù*). Removing them helps focus on more meaningful words during text analysis, improving the quality of the bag-of-words representation.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. What does the lambda function inside `apply()` do?**\n",
        "\n",
        "**Answer:**\n",
        "The lambda function processes each tagline (row) as follows:\n",
        "\n",
        "* Runs `nlp(row)` to tokenize and lemmatize it.\n",
        "* Keeps only words that are:\n",
        "\n",
        "  * Not stopwords\n",
        "  * Alphabetic (`isalpha()` removes punctuation/numbers)\n",
        "* Joins the cleaned lemmas back into a single string.\n",
        "\n",
        "This results in a **lemmatized and cleaned corpus** ready for vectorization.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. How is `bow_lem_matrix` different from `bow_matrix` in the previous example?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* **`bow_matrix`** used raw text (original taglines).\n",
        "* **`bow_lem_matrix`** uses **lemmatized and stopword-removed text**, making the matrix smaller and more semantically meaningful since similar words (like *‚Äúruns‚Äù, ‚Äúrunning‚Äù, ‚Äúran‚Äù*) are reduced to a single form (*‚Äúrun‚Äù*).\n",
        "\n",
        "---\n",
        "\n",
        "### **5. What does `bow_lem_matrix.shape` represent?**\n",
        "\n",
        "**Answer:**\n",
        "It prints a tuple `(number_of_taglines, number_of_unique_lemmatized_words)` ‚Äî showing how many taglines and unique cleaned words are present in the processed corpus.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_ULi7qJpyTAC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0qAj_q7QGQv"
      },
      "source": [
        "### Mapping feature indices with feature names\n",
        "n the lesson video, we had seen that `CountVectorizer` doesn't necessarily index the vocabulary in alphabetical order. In this exercise, we will learn to map each feature index to its corresponding feature name from the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjC21i1OQGQv"
      },
      "outputs": [],
      "source": [
        "sentences = ['The lion is the king of the jungle',\n",
        "             'Lions have lifespans of a decade',\n",
        "             'The lion is an endangered species']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sECN3qxQQGQv",
        "outputId": "04e8749e-ff08-4f1d-809c-44f1ca8218d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   an  decade  endangered  have  is  jungle  king  lifespans  lion  lions  of  \\\n",
              "0   0       0           0     0   1       1     1          0     1      0   1   \n",
              "1   0       1           0     1   0       0     0          1     0      1   1   \n",
              "2   1       0           1     0   1       0     0          0     1      0   0   \n",
              "\n",
              "   species  the  \n",
              "0        0    3  \n",
              "1        0    0  \n",
              "2        1    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ee9bebc-c7f8-412e-bb10-6f81018b077c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>decade</th>\n",
              "      <th>endangered</th>\n",
              "      <th>have</th>\n",
              "      <th>is</th>\n",
              "      <th>jungle</th>\n",
              "      <th>king</th>\n",
              "      <th>lifespans</th>\n",
              "      <th>lion</th>\n",
              "      <th>lions</th>\n",
              "      <th>of</th>\n",
              "      <th>species</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ee9bebc-c7f8-412e-bb10-6f81018b077c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ee9bebc-c7f8-412e-bb10-6f81018b077c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ee9bebc-c7f8-412e-bb10-6f81018b077c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e35e666-3ff5-4650-a2a4-c972c9985586\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e35e666-3ff5-4650-a2a4-c972c9985586')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e35e666-3ff5-4650-a2a4-c972c9985586 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4e1538c6-3d98-4b96-a2d7-47a439515366\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('bow_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e1538c6-3d98-4b96-a2d7-47a439515366 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('bow_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bow_df",
              "summary": "{\n  \"name\": \"bow_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"an\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decade\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"endangered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"have\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jungle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"king\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lifespans\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"of\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Create CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Generate matrix of word vectors\n",
        "bow_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "# Convert bow_matrix into a DataFrame\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray())\n",
        "\n",
        "# Map the column names to vocabulary\n",
        "bow_df.columns = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print bow_df\n",
        "bow_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLoiuuyfQGQw"
      },
      "source": [
        "Observe that the column names refer to the token whose frequency is being recorded. Therefore, since the first column name is an, the first feature represents the number of times the word `'an'` occurs in a particular sentence. `get_feature_names()` essentially gives us a list which represents the mapping of the feature indices to the feature name in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. What is happening in the `sentences` list?**\n",
        "\n",
        "**Answer:**\n",
        "The list `sentences` contains three short text strings that will be used as a **sample corpus**. Each sentence represents a document that the Bag-of-Words model will convert into numerical form.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What does `CountVectorizer()` do in this code?**\n",
        "\n",
        "**Answer:**\n",
        "`CountVectorizer` from `scikit-learn` transforms text into a **Bag-of-Words matrix**, where each column corresponds to a unique word and each row corresponds to a sentence.\n",
        "The cell values indicate **how many times** each word appears in a given sentence.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why use `vectorizer.get_feature_names_out()` instead of `get_feature_names()`?**\n",
        "\n",
        "**Answer:**\n",
        "`get_feature_names()` was **deprecated** in newer versions of scikit-learn (v1.0+).\n",
        "The correct method now is `get_feature_names_out()`, which returns the list of feature (word) names in the same order as the matrix columns.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What does `bow_matrix.toarray()` and `pd.DataFrame()` achieve?**\n",
        "\n",
        "**Answer:**\n",
        "`bow_matrix` is a **sparse matrix** (for memory efficiency).\n",
        "\n",
        "* `.toarray()` converts it into a dense NumPy array.\n",
        "* `pd.DataFrame()` converts it into a DataFrame for easier viewing and analysis, showing each word as a column and each sentence as a row.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. What kind of output does `bow_df` display?**\n",
        "\n",
        "**Answer:**\n",
        "The printed DataFrame (`bow_df`) shows the Bag-of-Words table. Example:\n",
        "\n",
        "|   | a | decade | endangered | have | is | jungle | king | lion | lions | of | species | the |\n",
        "| - | - | ------ | ---------- | ---- | -- | ------ | ---- | ---- | ----- | -- | ------- | --- |\n",
        "| 0 | 0 | 0      | 0          | 0    | 1  | 1      | 1    | 1    | 0     | 1  | 0       | 2   |\n",
        "| 1 | 1 | 1      | 0          | 1    | 0  | 0      | 0    | 0    | 1     | 1  | 0       | 0   |\n",
        "| 2 | 0 | 0      | 1          | 0    | 1  | 0      | 0    | 1    | 0     | 0  | 1       | 2   |\n",
        "\n",
        "Each cell shows how many times the word appears in that sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "r-On9l4zy5gQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rCwBOJcQGQw"
      },
      "source": [
        "## Building a BoW Naive Bayes classifier\n",
        "- Steps\n",
        "    1. Text preprocessing\n",
        "    2. Building a bag-of-words model (or representation)\n",
        "    3. Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDuXYB8bQGQw"
      },
      "source": [
        "### BoW vectors for movie reviews\n",
        "n this exercise, you have been given two pandas Series, `X_train` and `X_test`, which consist of movie reviews. They represent the training and the test review data respectively. Your task is to preprocess the reviews and generate BoW vectors for these two sets using `CountVectorizer`.\n",
        "\n",
        "Once we have generated the BoW vector matrices `X_train_bow` and `X_test_bow`, we will be in a very good position to apply a machine learning model to it and conduct sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWEbwKllQGQw",
        "outputId": "9a6f282a-8c3c-4ebb-a84d-1e7439ea8ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  this anime series starts out great interesting...          0\n",
              "1  some may go for a film like this but i most as...          0\n",
              "2  i ve seen this piece of perfection during the ...          1\n",
              "3  this movie is likely the worst movie i ve ever...          0\n",
              "4  it ll soon be 10 yrs since this movie was rele...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b89a5f92-8a6e-4709-81a2-a2f06693ec7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this anime series starts out great interesting...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>some may go for a film like this but i most as...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i ve seen this piece of perfection during the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this movie is likely the worst movie i ve ever...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it ll soon be 10 yrs since this movie was rele...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b89a5f92-8a6e-4709-81a2-a2f06693ec7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b89a5f92-8a6e-4709-81a2-a2f06693ec7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b89a5f92-8a6e-4709-81a2-a2f06693ec7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-18b4b118-4c6a-4a02-9d69-63ae282c9c93\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18b4b118-4c6a-4a02-9d69-63ae282c9c93')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-18b4b118-4c6a-4a02-9d69-63ae282c9c93 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_reviews",
              "summary": "{\n  \"name\": \"movie_reviews\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \" lies tells about an affair between an 18 year old bucktoothed female student and a scrawny 38 year old married man with the pair of protags spending about half the screen time engaged in naked sex and hokey whipping and the other half meandering through the pathetically naive storyline which seems little more than an excuse for the sex scenes with very poor production value including obvious sanitary appliances and phony softcore sex to a story which is a messy mix of comedy and drama lies quickly becomes redundant ad nauseam with an almost 2 hour run subtitles and so little substance lies is simply not recommendable c \",\n          \"chris penn is hilarious as the all time stoner brother of jeff spicoli this movie is great because it was a lot more real and funnier than fast times at ridgemont high casting was perfect and one of my favorite soundtracks of almost all eddie van halen which went on to become songs on ou812 and unlawful carnal knowledge this movie is one of the great stoner film heroes with cheech and chong fast times was more depressing than funny abortions friends cheating on friends jerking off in bathrooms bad jobs and failing school someone must hate the eighties to like ridgemont more than the wild life the film even had great cameos like the maker of city limits michelle schocked in the liquor store or ben stein in his first role in the sunny s surplus store \",\n          \"made after quartet was trio continued the quality of the earlier film versions of the short stories by maugham here the three stories are the verger mr know it all and sanitorium the first two are comic the verger is like a prolonged joke but one with a good pay off and the last more serious as health issues are involved again the author introduces the film and the stories james hayter soon to have his signature role as samuel pickwick is the hero in the verger he holds this small custodial type job in a church but the new vicar michael hordern is an intellectual snob when he hears hayter has no schooling he fires him hayter has saved some money so he tells his wife kathleen harrison he fancies buying a small news and tobacco shop he has a good eye and his store thrives soon he has a whole chain of stores when his grandchild is christened by hordern the latter is amazed to see how prosperous his ex verger the payoff is when bank manager felix aylmer meets with hayter about diversifying his investments i ll leave it to you to hear the unintentional but ironic coda of the meeting according to maugham he met a man like max kelada nigel patrick on a cruise in mr know it all kelada is a splashy friendly and slightly overbearing type from the middle east who is on a business trip regarding jewelry by steamship his state room mate is mr grey the ever quiet and proper wilfred hyde white who is somewhat silently disapproving of max max likes to enliven things and soon is heavily involved in the ship s entertainment at this point the story actually resembles part of the plot of the non maugham story and film china seas 1935 as max makes a bet that he can tell a real piece of jewelry from a fake after insisting that a piece of jewelry he spotted is real i won t describe the way max rises to the occasion sanitorium is the longest segment roland culver plays ashenden the fictional alter ego of maugham a writer and one time spy as in hitchcock s the secret agent here he has to use a sanitorium for a couple of months for his health he finds a remarkable crew of people including jean simmons as a frail but beautiful young woman finlay currie as an irascible scotsman john laurie as a second irascible scotsman who is at war with currie raymond huntley as a quiet patient who only shows his internal anger at his situation when his wife shows up and michael rennie as a young man who has a serious life threatening illness culver watches as three stories among these characters play out to their conclusions the last dealing with simmons and rennie is ironic but deeply moving it was a dandy follow up to the earlier quartet and well worth watching \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "movie_reviews = pd.read_csv('movie_reviews_clean.csv')\n",
        "movie_reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcIgNEyBQGQw"
      },
      "outputs": [],
      "source": [
        "X = movie_reviews['review']\n",
        "y = movie_reviews['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2BPV7AdQGQw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqh9j8h-QGQw",
        "outputId": "fae79ab2-a32a-401a-d43f-07d65a245d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(750, 15068)\n",
            "(250, 15068)\n"
          ]
        }
      ],
      "source": [
        "# Create a CounterVectorizer object\n",
        "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
        "\n",
        "# fit and transform X_train\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform X_test\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Print shape of X_train_bow and X_test_bow\n",
        "print(X_train_bow.shape)\n",
        "print(X_test_bow.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. What is the purpose of splitting `X` and `y` using `train_test_split()`?**\n",
        "\n",
        "**Answer:**\n",
        "`train_test_split()` divides the dataset into:\n",
        "\n",
        "* **Training set (`X_train`, `y_train`)** ‚Üí used to train the model\n",
        "* **Testing set (`X_test`, `y_test`)** ‚Üí used to evaluate performance on unseen data\n",
        "  The `test_size=0.25` means 25% of the data will be reserved for testing, and 75% for training.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What does the `CountVectorizer(lowercase=True, stop_words='english')` do?**\n",
        "\n",
        "**Answer:**\n",
        "It converts text into numerical form (Bag-of-Words) with two preprocessing steps:\n",
        "\n",
        "* `lowercase=True`: converts all words to lowercase for uniformity\n",
        "* `stop_words='english'`: removes common English words (like ‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúan‚Äù) that don‚Äôt add meaning to sentiment classification\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why do we use `fit_transform()` on `X_train` but only `transform()` on `X_test`?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* `fit_transform(X_train)` learns the **vocabulary** from the training data and transforms it into word counts.\n",
        "* `transform(X_test)` uses the **same learned vocabulary** to convert test data ‚Äî ensuring consistency between training and testing features.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What do `X_train_bow.shape` and `X_test_bow.shape` tell us?**\n",
        "\n",
        "**Answer:**\n",
        "They show the dimensions of the Bag-of-Words matrices:\n",
        "\n",
        "* Rows = number of samples (reviews)\n",
        "* Columns = number of unique words in the vocabulary (features)\n",
        "  Example output:\n",
        "\n",
        "```\n",
        "(1500, 8000)\n",
        "(500, 8000)\n",
        "```\n",
        "\n",
        "This means there are 1500 training reviews and 500 testing reviews, with 8000 unique words represented as features.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Why use Bag-of-Words before building a sentiment analysis model?**\n",
        "\n",
        "**Answer:**\n",
        "The Bag-of-Words (BoW) model converts raw text into numerical vectors that machine learning models (like Naive Bayes, Logistic Regression, or SVM) can process to **learn patterns** associated with positive or negative sentiments.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MyJ0oTdkzxed"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4K3tOOaQGQw"
      },
      "source": [
        "You now have a good idea of preprocessing text and transforming them into their bag-of-words representation using `CountVectorizer`. In this exercise, you have set the lowercase argument to True. However, note that this is the default value of lowercase and passing it explicitly is not necessary. Also, note that both `X_train_bow` and `X_test_bow` have 7822 features. There were words present in `X_test` that were not in `X_train`. CountVectorizer chose to ignore them in order to ensure that the dimensions of both sets remain the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNDRW09kQGQx"
      },
      "source": [
        "### Predicting the sentiment of a movie review\n",
        "n the previous exercise, you generated the bag-of-words representations for the training and test movie review data. In this exercise, we will use this model to train a Naive Bayes classifier that can detect the sentiment of a movie review and compute its accuracy. Note that since this is a binary classification problem, the model is only capable of classifying a review as either positive (1) or negative (0). It is incapable of detecting neutral reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBoZIP_HQGQx",
        "outputId": "ced3b68e-1d19-45e9-a636-608ef70e4a3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the classifier on the test set is 0.828\n",
            "The sentiment predicted by the classifier is 0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Create a MultinomialNB object\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# Fit the classifier\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "# Measure the accuracy\n",
        "accuracy = clf.score(X_test_bow, y_test)\n",
        "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
        "\n",
        "# Predict the sentiment of a negative review\n",
        "review = 'The movie was terrible. The music was underwhelming and the acting mediocre.'\n",
        "prediction = clf.predict(vectorizer.transform([review]))[0]\n",
        "print(\"The sentiment predicted by the classifier is %i\" % (prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. Why do we use `MultinomialNB` for text classification?**\n",
        "\n",
        "**Answer:**\n",
        "`MultinomialNB` is ideal for **text data** represented as **word counts (Bag-of-Words)**.\n",
        "It assumes features (word frequencies) follow a multinomial distribution, making it effective for tasks like **spam detection** or **sentiment analysis**, where input data are discrete word counts.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What happens in `clf.fit(X_train_bow, y_train)`?**\n",
        "\n",
        "**Answer:**\n",
        "This trains the Naive Bayes classifier using the training Bag-of-Words features (`X_train_bow`) and their corresponding sentiment labels (`y_train`).\n",
        "During training, the model learns **probabilities of words appearing in positive vs. negative reviews**.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. How does `clf.score(X_test_bow, y_test)` measure accuracy?**\n",
        "\n",
        "**Answer:**\n",
        "It evaluates the classifier on unseen test data by comparing predicted labels against true labels.\n",
        "It returns a **fraction (between 0 and 1)** representing how many reviews were correctly classified.\n",
        "Example output:\n",
        "\n",
        "```\n",
        "The accuracy of the classifier on the test set is 0.842\n",
        "```\n",
        "\n",
        "means 84.2% of test reviews were correctly classified.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. How does the classifier predict sentiment for a new review?**\n",
        "\n",
        "**Answer:**\n",
        "The review is first transformed into a Bag-of-Words vector using the same `vectorizer`:\n",
        "\n",
        "```python\n",
        "vectorizer.transform([review])\n",
        "```\n",
        "\n",
        "Then `clf.predict()` uses learned word probabilities to assign a label (e.g., `1` for positive, `0` for negative).\n",
        "\n",
        "---\n",
        "\n",
        "### **5. What does the printed sentiment value (`%i`) mean?**\n",
        "\n",
        "**Answer:**\n",
        "The predicted sentiment (`prediction`) is usually:\n",
        "\n",
        "* **1 ‚Üí Positive review**\n",
        "* **0 ‚Üí Negative review**\n",
        "  So if output is:\n",
        "\n",
        "```\n",
        "The sentiment predicted by the classifier is 0\n",
        "```\n",
        "\n",
        "it means the model considers the review negative.\n",
        "\n"
      ],
      "metadata": {
        "id": "014o1MDJ0J_q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRwcmVfFQGQx"
      },
      "source": [
        "You have successfully performed basic sentiment analysis. Note that the accuracy of the classifier is 80%. Considering the fact that it was trained on only 750 reviews, this is reasonably good performance. The classifier also correctly predicts the sentiment of a mini negative review which we passed into it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRHKFBnPQGQx"
      },
      "source": [
        "## Building n-gram models\n",
        "- BoW shortcomings\n",
        "    - Example\n",
        "        - `The movie was good and not boring` -> positive\n",
        "        - `The movie was not good and boring` -> negative\n",
        "    - Exactly the same BoW representation!\n",
        "    - Context of the words is lost.\n",
        "    - Sentiment dependent on the position of `not`\n",
        "- n-grams\n",
        "    - Contiguous sequence of n elements (or words) in a given document.\n",
        "    - Bi-grams / Tri-grams\n",
        "- n-grams Shortcomings\n",
        "    - Increase number of dimension, occurs curse of dimensionality\n",
        "    - Higher order n-grams are rare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AamO3zxQGQx"
      },
      "source": [
        "### n-gram models for movie tag lines\n",
        "In this exercise, we have been provided with a corpus of more than 9000 movie tag lines. Our job is to generate n-gram models up to n equal to 1, n equal to 2 and n equal to 3 for this data and discover the number of features for each model.\n",
        "\n",
        "We will then compare the number of features generated for each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNmw3MGtQGQx",
        "outputId": "281eccc0-160f-422e-eeb5-4ecfdaaba824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ng1, ng2 and ng3 have 6614, 37100 and 76881 features respectively\n"
          ]
        }
      ],
      "source": [
        "# Generate n-grams upto n=1\n",
        "vectorizer_ng1 = CountVectorizer(ngram_range=(1, 1))\n",
        "ng1 = vectorizer_ng1.fit_transform(corpus)\n",
        "\n",
        "# Generate n-grams upto n=2\n",
        "vectorizer_ng2 = CountVectorizer(ngram_range=(1, 2))\n",
        "ng2 = vectorizer_ng2.fit_transform(corpus)\n",
        "\n",
        "# Generate n-grams upto n=3\n",
        "vectorizer_ng3 = CountVectorizer(ngram_range=(1, 3))\n",
        "ng3 = vectorizer_ng3.fit_transform(corpus)\n",
        "\n",
        "# Print the number of features for each model\n",
        "print(\"ng1, ng2 and ng3 have %i, %i and %i features respectively\" %\n",
        "      (ng1.shape[1], ng2.shape[1], ng3.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1. What does `ngram_range=(1, 1)`, `(1, 2)`, and `(1, 3)` mean?**\n",
        "\n",
        "**Answer:**\n",
        "These specify the **range of n-grams** to extract:\n",
        "\n",
        "* `(1, 1)` ‚Üí only **unigrams** (single words)\n",
        "* `(1, 2)` ‚Üí **unigrams + bigrams** (single words and 2-word phrases)\n",
        "* `(1, 3)` ‚Üí **unigrams + bigrams + trigrams** (up to 3-word phrases)\n",
        "  This allows the model to capture short word sequences that may carry more context or meaning.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What are n-grams in natural language processing?**\n",
        "\n",
        "**Answer:**\n",
        "An **n-gram** is a sequence of *n* consecutive words from text.\n",
        "Example (for the sentence *\"The lion roars loudly\"*):\n",
        "\n",
        "* Unigrams: `[\"The\", \"lion\", \"roars\", \"loudly\"]`\n",
        "* Bigrams: `[\"The lion\", \"lion roars\", \"roars loudly\"]`\n",
        "* Trigrams: `[\"The lion roars\", \"lion roars loudly\"]`\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why does the number of features increase when n-gram range increases?**\n",
        "\n",
        "**Answer:**\n",
        "Higher-order n-grams create additional features for every possible word combination.\n",
        "So, `ng2` and `ng3` contain many more columns than `ng1`, since they include multi-word expressions (e.g., ‚Äúgood movie‚Äù, ‚Äúvery good movie‚Äù), expanding the vocabulary size.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What does the line printing feature counts show?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "```python\n",
        "print(\"ng1, ng2 and ng3 have %i, %i and %i features respectively\" %\n",
        "      (ng1.shape[1], ng2.shape[1], ng3.shape[1]))\n",
        "```\n",
        "\n",
        "It prints how many **unique features (n-grams)** each CountVectorizer generated.\n",
        "Example output:\n",
        "\n",
        "```\n",
        "ng1, ng2 and ng3 have 500, 2500 and 6000 features respectively\n",
        "```\n",
        "\n",
        "shows that higher n-gram ranges drastically increase the dimensionality.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. When should we use higher n-grams (like 2 or 3)?**\n",
        "\n",
        "**Answer:**\n",
        "Use **bigrams/trigrams** when:\n",
        "\n",
        "* Context or word order affects meaning (e.g., *‚Äúnot good‚Äù*, *‚Äúvery bad movie‚Äù*).\n",
        "  Avoid them when the dataset is small, since more n-grams increase sparsity and may lead to **overfitting** or slower computation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PWzSBj8h0hMP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D881no8BQGQx"
      },
      "source": [
        "You now know how to generate n-gram models containing higher order n-grams. Notice that `ng2` has over 37,000 features whereas `ng3` has over 76,000 features. This is much greater than the 6,000 dimensions obtained for `ng1`. As the n-gram range increases, so does the number of features, leading to increased computational costs and a problem known as the curse of dimensionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1RPghvpQGQx"
      },
      "source": [
        "### Higher order n-grams for sentiment analysis\n",
        "Similar to a previous exercise, we are going to build a classifier that can detect if the review of a particular movie is positive or negative. However, this time, we will use n-grams up to n=2 for the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLbGV9tcQGQ2"
      },
      "outputs": [],
      "source": [
        "ng_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "X_train_ng = ng_vectorizer.fit_transform(X_train)\n",
        "X_test_ng = ng_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjtWatS9QGQ2",
        "outputId": "d604b8a3-6c3b-4d43-e591-cad08aa6fc9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the classifier on the test set is 0.836\n",
            "The sentiment predicted by the classifier is 0\n"
          ]
        }
      ],
      "source": [
        "# Define an instance of MultinomialNB\n",
        "clf_ng = MultinomialNB()\n",
        "\n",
        "# Fit the classifier\n",
        "clf_ng.fit(X_train_ng, y_train)\n",
        "\n",
        "# Measure the accuracy\n",
        "accuracy = clf_ng.score(X_test_ng, y_test)\n",
        "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
        "\n",
        "# Predict the sentiment of a negative review\n",
        "review = 'The movie was not good. The plot had several holes and the acting lacked panache'\n",
        "prediction = clf_ng.predict(ng_vectorizer.transform([review]))[0]\n",
        "print(\"The sentiment predicted by the classifier is %i\" % (prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. Why is `ngram_range=(1, 2)` used in `CountVectorizer`?**\n",
        "\n",
        "**Answer:**\n",
        "Setting `ngram_range=(1, 2)` makes the vectorizer capture both **unigrams (single words)** and **bigrams (two-word combinations)**.\n",
        "This helps the model understand short phrases like *‚Äúnot good‚Äù* or *‚Äúvery bad‚Äù*, which convey stronger sentiment than single words alone.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. How does using n-grams improve model performance?**\n",
        "\n",
        "**Answer:**\n",
        "N-grams capture **context and word relationships**, allowing the model to better interpret phrases that change meaning based on combination (e.g., ‚Äúnot great‚Äù vs. ‚Äúgreat‚Äù).\n",
        "This typically increases accuracy compared to using only unigrams ‚Äî though it also increases the number of features.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. What happens when `fit_transform()` and `transform()` are used here?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* `fit_transform(X_train)` ‚Üí learns the vocabulary (including unigrams + bigrams) **and** transforms the training data.\n",
        "* `transform(X_test)` ‚Üí transforms the test data using the **same vocabulary**, ensuring feature consistency between training and testing.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What does the printed accuracy represent?**\n",
        "\n",
        "**Answer:**\n",
        "The accuracy value (e.g., `0.875`) shows the **percentage of correctly predicted sentiments** on the test set.\n",
        "Higher accuracy compared to the unigram model usually means n-grams helped capture more nuanced sentiment cues.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. How does the classifier handle a new review prediction?**\n",
        "\n",
        "**Answer:**\n",
        "The new review is converted into its n-gram feature representation using:\n",
        "\n",
        "```python\n",
        "ng_vectorizer.transform([review])\n",
        "```\n",
        "\n",
        "Then `clf_ng.predict()` outputs the sentiment label:\n",
        "\n",
        "* **1 ‚Üí Positive review**\n",
        "* **0 ‚Üí Negative review**\n",
        "\n",
        "Example output:\n",
        "\n",
        "```\n",
        "The sentiment predicted by the classifier is 0\n",
        "```\n",
        "\n",
        "indicates that the model found the review negative.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P04HX3iJ1Edy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jKy7q0-QGQ2"
      },
      "source": [
        "Notice how this classifier performs slightly better than the BoW version. Also, it succeeds at correctly identifying the sentiment of the mini-review as negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90aWOrnDQGQ2"
      },
      "source": [
        "### Comparing performance of n-gram models\n",
        "You now know how to conduct sentiment analysis by converting text into various n-gram representations and feeding them to a classifier. In this exercise, we will conduct sentiment analysis for the same movie reviews from before using two n-gram models: unigrams and n-grams upto n equal to 3.\n",
        "\n",
        "We will then compare the performance using three criteria: accuracy of the model on the test set, time taken to execute the program and the number of features created when generating the n-gram representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iEIqEXdQGQ2",
        "outputId": "14b50457-3cdd-42f0-a431-ea9b96421f4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The program took 0.368 seconds to complete. The accuracy on the test set is 0.75. \n",
            "The ngram representation had 12347 features.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(movie_reviews['review'],\n",
        "                                                    movie_reviews['sentiment'],\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=movie_reviews['sentiment'])\n",
        "\n",
        "# Generateing ngrams\n",
        "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
        "train_X = vectorizer.fit_transform(train_X)\n",
        "test_X = vectorizer.transform(test_X)\n",
        "\n",
        "# Fit classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "# Print the accuracy, time and number of dimensions\n",
        "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. \" %\n",
        "      (time.time() - start_time, clf.score(test_X, test_y)))\n",
        "print(\"The ngram representation had %i features.\" % (train_X.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPUXi6YhQGQ3",
        "outputId": "74cd4839-2581-42f7-d071-fd327efe6a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The program took 1.675 seconds to complete. The accuracy on the test set is 0.77. \n",
            "The ngram representation had 178240 features.\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(movie_reviews['review'],\n",
        "                                                    movie_reviews['sentiment'],\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=movie_reviews['sentiment'])\n",
        "\n",
        "# Generateing ngrams\n",
        "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
        "train_X = vectorizer.fit_transform(train_X)\n",
        "test_X = vectorizer.transform(test_X)\n",
        "\n",
        "# Fit classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "# Print the accuracy, time and number of dimensions\n",
        "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. \" %\n",
        "      (time.time() - start_time, clf.score(test_X, test_y)))\n",
        "print(\"The ngram representation had %i features.\" % (train_X.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **1. Why are we measuring both accuracy and time?**\n",
        "\n",
        "**Answer:**\n",
        "Measuring **accuracy** shows how well the model predicts sentiments, while measuring **time** helps evaluate how computationally expensive it is.\n",
        "This comparison helps determine the trade-off between **model performance** (accuracy) and **efficiency** (speed).\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why does the code use two CountVectorizers ‚Äî one with `(1,1)` and one with `(1,3)`?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* `(1,1)` generates **unigrams** (single words).\n",
        "* `(1,3)` generates **unigrams, bigrams, and trigrams** (phrases up to 3 words).\n",
        "  The goal is to see how including longer word sequences affects the classifier‚Äôs **accuracy and runtime**.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why does the program take longer with `(1,3)` n-grams?**\n",
        "\n",
        "**Answer:**\n",
        "Adding bigrams and trigrams drastically increases the **number of features** (unique word combinations).\n",
        "This leads to:\n",
        "\n",
        "* Larger matrices\n",
        "* More computations during training and prediction\n",
        "  Hence, **higher runtime and memory usage**, even though it might improve accuracy slightly.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. What does `train_X.shape[1]` tell us?**\n",
        "\n",
        "**Answer:**\n",
        "It gives the **number of features (columns)** in the n-gram representation ‚Äî i.e., the total number of unique tokens or token combinations.\n",
        "For example:\n",
        "\n",
        "```\n",
        "The ngram representation had 12,500 features.\n",
        "```\n",
        "\n",
        "means there were 12,500 distinct unigrams/bigrams/trigrams in the training data.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Why is `stratify=movie_reviews['sentiment']` used in `train_test_split()`?**\n",
        "\n",
        "**Answer:**\n",
        "`stratify` ensures that both training and test sets maintain the **same proportion of positive and negative reviews** as the original dataset.\n",
        "This helps avoid biased splits that could distort model accuracy or evaluation.\n",
        "\n"
      ],
      "metadata": {
        "id": "qfUpU2F72Grx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUL4DzG2QGQ3"
      },
      "source": [
        "The program took around 0.2 seconds in the case of the unigram model and more than 10 times longer for the higher order n-gram model. The unigram model had over 12,000 features whereas the n-gram model for upto n=3 had over 178,000! Despite taking higher computation time and generating more features, the classifier only performs marginally better in the latter case, producing an accuracy of 77% in comparison to the 75% for the unigram model."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}